{"version":3,"kind":"Article","sha256":"c002fec9508bb15d0245e0f0be9df4caf75b3830aa9b1a6be36028cb0a63a582","slug":"training","location":"/core/common_tasks/training.md","dependencies":[],"frontmatter":{"title":"Training Models from Scratch","content_includes_title":false,"authors":[{"nameParsed":{"literal":"FAIR Chemistry & Collaborators","given":"FAIR Chemistry &","family":"Collaborators"},"name":"FAIR Chemistry & Collaborators","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/facebookresearch/fairchem","copyright":"Meta Platforms, Inc","numbering":{"title":{"offset":2}},"source_url":"https://github.com/facebookresearch/fairchem/blob/main/docs/core/common_tasks/training.md","edit_url":"https://github.com/facebookresearch/fairchem/edit/main/docs/core/common_tasks/training.md","exports":[{"format":"md","filename":"training.md","url":"/build/training-0cd95448854b060100f3a275074d8d27.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This repo is used to train large state-of-the-art graph neural networks from scratch on datasets like OC20, OMol25, or OMat24, among others.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Y5DxJsHgLa"}],"key":"c7rAQqbzQ1"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"oMXOSfLfpa"}],"key":"Bc6lelby0Z"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"We now provide a simple CLI to handle this using your own custom datasets, but we suggest fine-tuning one of the existing checkpoints first before trying a from-scratch training.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"i4kAwK1LEp"}],"key":"HGbB3Fju0c"}],"key":"Nyi7blPzaj"},{"type":"heading","depth":2,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"FAIRChem Training Framework Overview","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"VrEWO4IdE5"}],"identifier":"fairchem-training-framework-overview","label":"FAIRChem Training Framework Overview","html_id":"fairchem-training-framework-overview","implicit":true,"key":"voJ50MgIqj"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"The FAIRChem training framework currently uses a simple SPMD (Single Program Multiple Data) paradigm. It is made of several components:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"mTiedov2Tm"}],"key":"pix0EzgqAl"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"User CLI and Launcher","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"cNUrLNz7rA"}],"key":"iL9recIrAB"},{"type":"text","value":" - The ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"oy9QHlHLSg"},{"type":"inlineCode","value":"fairchem","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"zlIfbjJfkL"},{"type":"text","value":" CLI can run jobs locally using ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"lMup25ATU2"},{"type":"link","url":"https://docs.pytorch.org/docs/stable/distributed.elastic.html","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"torch distributed elastic","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"oAIeF43vkg"}],"urlSource":"https://docs.pytorch.org/docs/stable/distributed.elastic.html","key":"DEZuqCl7Dj"},{"type":"text","value":" or on ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"I0wlL2dKiS"},{"type":"link","url":"https://slurm.schedmd.com/documentation.html","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"SLURM","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"hqvUWsV81z"}],"urlSource":"https://slurm.schedmd.com/documentation.html","key":"KAvguNzdvU"},{"type":"text","value":". More environments may be supported in the future.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Vr9pv2YFXb"}],"key":"mlIpxZjZ9d"}],"key":"DSFjibf094"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Configuration","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"XC5rn8r4rL"}],"key":"xy8cyyYxLe"},{"type":"text","value":" - We strictly use ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"FbWAZIOga3"},{"type":"link","url":"https://hydra.cc/docs/intro/","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Hydra YAMLs","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"COmhOYr7As"}],"urlSource":"https://hydra.cc/docs/intro/","key":"N2Tn7Jywso"},{"type":"text","value":" for configuration.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"L8YQvZTXZf"}],"key":"VWKgI2c1rh"}],"key":"yjC5l39Oyy"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"strong","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Runner Interface","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"fHtZymcNiX"}],"key":"EQ9rYTsPgl"},{"type":"text","value":" - The core program code that is replicated to run on all ranks. An optional Reducer is also available for evaluation jobs. Runners are distinct user functions that run on a single rank (i.e., GPU). They describe separate high-level tasks such as Train, Eval, Predict, Relaxations, MD, etc. Anyone can write a new runner if its functionality is sufficiently different than the ones that already exist.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"N2m5luxusk"}],"key":"NcvS9QuWeX"}],"key":"vrmDIeazf4"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Trainer","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"pLZWtGNCKv"}],"key":"kKqPMq1GqL"},{"type":"text","value":" - We use ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"oDyC75tMGS"},{"type":"link","url":"https://docs.pytorch.org/tnt/stable/","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"TorchTNT","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"aaq0TufBZm"}],"urlSource":"https://docs.pytorch.org/tnt/stable/","key":"baTr4cjsDc"},{"type":"text","value":" as a light-weight training loop. This allows us to cleanly separate the data loading from the training loop.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"X23KLFZzo4"}],"key":"RSNEVgtJud"}],"key":"JnUsB0OduB"}],"key":"YltHJwIzsI"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"fvfXmdjSBq"}],"key":"DTbsXa4mxb"},{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"TNT is PyTorch’s replacement for PyTorch Lightning - which has become severely bloated and difficult to use over the years; so we opted for the simpler option. Units are concepts in TorchTNT that provide a basic interface for training, evaluation, and prediction. These replace trainers in fairchemv1. You should write a new unit when the model paradigm is significantly different, e.g., training a Multitask-MLIP is one unit, training a diffusion model should be another unit.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"gJ7AGWvZUe"}],"key":"WpviI0kwyF"}],"key":"p1przahMRL"},{"type":"heading","depth":2,"position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"FAIRChem v2 CLI","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"lljcJsH2Ls"}],"identifier":"fairchem-v2-cli","label":"FAIRChem v2 CLI","html_id":"fairchem-v2-cli","implicit":true,"key":"g2418lXScv"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"FAIRChem uses a single ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"YZczYFR3st"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/_cli.py","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"CLI","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"atc7lFT54u"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/_cli.py","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/_cli.py","raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/_cli.py"},"internal":false,"protocol":"github","key":"YjPlHURwIH"},{"type":"text","value":" for running jobs. It accepts a single argument, the location of the Hydra YAML.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"oFfUsGjvPR"}],"key":"RXPtii2FKq"},{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Warning","key":"IEAJasOVSG"}],"key":"f4hmipflGO"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"This is intentional to make sure all configuration is fully captured and avoid bloating of the command line interface. Because of the flexibility of Hydra YAMLs, you can still provide additional parameters and overrides using the ","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"YvmhgXwYux"},{"type":"link","url":"https://hydra.cc/docs/advanced/override_grammar/basic/","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Hydra override syntax","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"sctLXvWJZt"}],"urlSource":"https://hydra.cc/docs/advanced/override_grammar/basic/","key":"qpJW4oOw0R"},{"type":"text","value":".","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"y0821PI2Ui"}],"key":"BLkAnwI5Sb"}],"key":"iljpvprHnR"},{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"The CLI can launch jobs locally using ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"whw91fQkha"},{"type":"link","url":"https://docs.pytorch.org/docs/stable/distributed.elastic.html","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"torch distributed elastic","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"zeVndpYfAL"}],"urlSource":"https://docs.pytorch.org/docs/stable/distributed.elastic.html","key":"wpY6udn4Ng"},{"type":"text","value":" OR on ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"TOuXyIVn9C"},{"type":"link","url":"https://slurm.schedmd.com/documentation.html","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"SLURM","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"ydgEpkanJP"}],"urlSource":"https://slurm.schedmd.com/documentation.html","key":"tix3m1I66t"},{"type":"text","value":".","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"TUcYaHmSMn"}],"key":"hzhYDXZqh8"},{"type":"heading","depth":3,"position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"FAIRChem v2 Config Structure","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"FgnHk12ONr"}],"identifier":"fairchem-v2-config-structure","label":"FAIRChem v2 Config Structure","html_id":"fairchem-v2-config-structure","implicit":true,"key":"FM725phmgb"},{"type":"paragraph","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"A FAIRChem config is composed of only 2 valid top-level keys: ","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"mGM2Prgib9"},{"type":"strong","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"job","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"vU5O064sXi"}],"key":"WNA7fbWQGE"},{"type":"text","value":" (Job Config) and ","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"Tqaa9QnkMj"},{"type":"strong","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"runner","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"MDDx2FLEcB"}],"key":"OjbrnguT23"},{"type":"text","value":" (Runner Config). Additionally, you can add key/values that are used by the OmegaConf interpolation syntax to replace fields. Other than these, no other top-level keys are permitted.","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"ex9PIY0IIv"}],"key":"TP8kaerqed"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":40,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"JobConfig","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"Sd4hnJkjMh"}],"key":"QpUai6PWFY"},{"type":"text","value":" represents configuration parameters that describe the overall job (mostly infra parameters) such as number of nodes, log locations, loggers, etc. This is a structured config and must strictly adhere to the JobConfig class.","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"OCosnJtgzh"}],"key":"qFD8p61M1I"}],"key":"c35aZcsUUM"},{"type":"listItem","spread":true,"position":{"start":{"line":41,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Runner Config","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"XNU2GIsFc9"}],"key":"LbZ2IhDOY5"},{"type":"text","value":" describes the user code. This part of config is recursively instantiated at the start of a job using Hydra instantiation framework.","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"QQUk6kccTL"}],"key":"fDuLyHkIB7"}],"key":"GxO3TvafaJ"}],"key":"gJwPSC4Nk7"},{"type":"heading","depth":3,"position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"Example Configurations","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"MDXv5Zew8M"}],"identifier":"example-configurations","label":"Example Configurations","html_id":"example-configurations","implicit":true,"key":"ulsRVJ59om"},{"type":"paragraph","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"strong","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"Local run:","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"m8XghrYC1S"}],"key":"QaVcGROxBC"}],"key":"bY2vX3SXxj"},{"type":"code","lang":"yaml","value":"job:\n  device_type: CUDA\n  scheduler:\n    mode: LOCAL\n    ranks_per_node: 4\n  run_name: local_training_run","position":{"start":{"line":47,"column":1},"end":{"line":54,"column":1}},"key":"ZzbIOIyQHy"},{"type":"paragraph","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"strong","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"SLURM run:","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"b9UMRUPMjH"}],"key":"gElFMlfbfA"}],"key":"JXKcpos8Rb"},{"type":"code","lang":"yaml","value":"job:\n  device_type: CUDA\n  scheduler:\n    mode: SLURM\n    ranks_per_node: 8\n    num_nodes: 4\n    slurm:\n      account: ${cluster.account}\n      qos: ${cluster.qos}\n      mem_gb: ${cluster.mem_gb}\n      cpus_per_task: ${cluster.cpus_per_task}\n  run_dir: /path/to/output\n  run_name: slurm_run_example","position":{"start":{"line":58,"column":1},"end":{"line":72,"column":1}},"key":"Jg5WLX1ZiG"},{"type":"heading","depth":3,"position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"text","value":"Config Object Instantiation","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"G8E6dCrcWO"}],"identifier":"config-object-instantiation","label":"Config Object Instantiation","html_id":"config-object-instantiation","implicit":true,"key":"izJNLR7I7e"},{"type":"paragraph","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"To keep our configs explicit (configs should be thought of as an extension of code), we prefer to use the Hydra instantiation framework throughout; the config is always fully described by a corresponding Python class and should never be a standalone dictionary.","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"NpbAu9BO5t"}],"key":"mFf9ZtmS4G"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Good vs Bad Config Patterns","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"azlOX54y4n"}],"key":"c4acXbfXmA"},{"type":"paragraph","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"strong","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"text","value":"Bad pattern","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"key":"PXXGgdXLts"}],"key":"JOBGke5FRi"},{"type":"text","value":" - We have no idea where to find the code that uses runner or where variables x and y are actually used:","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"key":"HZSVsIHP20"}],"key":"ZXdDgFMHBr"},{"type":"code","lang":"yaml","value":"runner:\n  x: 5\n  y: 6","position":{"start":{"line":83,"column":1},"end":{"line":87,"column":1}},"key":"I4rNwLNerl"},{"type":"paragraph","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"strong","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"text","value":"Good pattern","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"JdJmbsgNb9"}],"key":"wGVyOKD6qo"},{"type":"text","value":" - Now we know which class runner corresponds to and that x, y are just initializer variables of runner. If we need to check the definition or understand the code, we can simply go to runner.py:","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"KWECDX96Nf"}],"key":"phInS8cud7"},{"type":"code","lang":"yaml","value":"runner:\n  _target_: fairchem.core.components.runner.Runner\n  x: 5\n  y: 6","position":{"start":{"line":91,"column":1},"end":{"line":96,"column":1}},"key":"GDTUGYZgm8"}],"class":"dropdown","key":"Hgtvm9eZXJ"},{"type":"heading","depth":3,"position":{"start":{"line":99,"column":1},"end":{"line":99,"column":1}},"children":[{"type":"text","value":"Runtime Instantiation with Partial Functions","position":{"start":{"line":99,"column":1},"end":{"line":99,"column":1}},"key":"aIoXXJIRBW"}],"identifier":"runtime-instantiation-with-partial-functions","label":"Runtime Instantiation with Partial Functions","html_id":"runtime-instantiation-with-partial-functions","implicit":true,"key":"vFFcjodRun"},{"type":"paragraph","position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"children":[{"type":"text","value":"While we want to use static instantiation as much as possible, there will be many cases where certain objects require runtime inputs to create. For example, if we want to create a PyTorch optimizer, we can give it all the arguments except the model parameters (because it’s only known at runtime).","position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"key":"HJbCIK5lrr"}],"key":"dLXL73L1VZ"},{"type":"code","lang":"yaml","value":"optimizer:\n  _target_: torch.optim.AdamW\n  params: ?? # this is only known at runtime\n  lr: 8e-4\n  weight_decay: 1e-3","position":{"start":{"line":103,"column":1},"end":{"line":109,"column":1}},"key":"IUdbyp2saY"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"RELsonImnB"}],"key":"sMywRiqMCs"},{"type":"paragraph","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"In this case we can use a partial function. Instead of creating an optimizer object, we create a Python partial function that can then be used to instantiate the optimizer in code later:","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"P4ukQuRBmR"}],"key":"AGeRdnecNN"}],"key":"RTkQmgqt2T"},{"type":"code","lang":"yaml","value":"optimizer_fn:\n  _target_: torch.optim.AdamW\n  _partial_: true\n  lr: 8e-4\n  weight_decay: 1e-3","position":{"start":{"line":115,"column":1},"end":{"line":121,"column":1}},"key":"FcsZmMfecL"},{"type":"code","lang":"python","value":"# later in the runner\noptimizer = optimizer_fn(model.parameters())","position":{"start":{"line":123,"column":1},"end":{"line":126,"column":1}},"key":"AjuEze3zu2"},{"type":"heading","depth":2,"position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"children":[{"type":"text","value":"Training UMA","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"key":"aRSoQiWOhe"}],"identifier":"training-uma","label":"Training UMA","html_id":"training-uma","implicit":true,"key":"Et52aqnwr2"},{"type":"paragraph","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"children":[{"type":"text","value":"The UMA model is completely defined ","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"key":"BUdga5IgaN"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/tree/main/src/fairchem/core/models/uma","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"children":[{"type":"text","value":"here","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"key":"AF9SODHYrV"}],"urlSource":"https://github.com/facebookresearch/fairchem/tree/main/src/fairchem/core/models/uma","error":true,"key":"sx6w61843X"},{"type":"text","value":". It is also called “escn_md” during internal development since it was based on the eSEN architecture.","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"key":"RceOtcI1Di"}],"key":"odQ67cdzko"},{"type":"paragraph","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"children":[{"type":"text","value":"Training, evaluation, and inference are all defined in the ","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"iaM2H0J3X8"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/mlip_unit.py","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"children":[{"type":"text","value":"mlip unit","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"ZvwbsCmSzk"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/mlip_unit.py","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/units/mlip_unit/mlip_unit.py","raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/units/mlip_unit/mlip_unit.py"},"internal":false,"protocol":"github","key":"n38tiHbgYJ"},{"type":"text","value":".","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"h3Ec0kyEuJ"}],"key":"afhMTAWSgz"},{"type":"paragraph","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"text","value":"To train a model, we need to initialize a ","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"tzgGYVI1DU"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/components/train/train_runner.py","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"text","value":"TrainRunner","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"K0KFbPYdGq"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/components/train/train_runner.py","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/components/train/train_runner.py","raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/components/train/train_runner.py"},"internal":false,"protocol":"github","key":"usP46T3Aee"},{"type":"text","value":" with a ","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"K8qxyxghdQ"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/mlip_unit.py","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"text","value":"MLIPTrainEvalUnit","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"RW6E0z8ads"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/mlip_unit.py","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/units/mlip_unit/mlip_unit.py","raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/units/mlip_unit/mlip_unit.py"},"internal":false,"protocol":"github","key":"vDVrn0sWJA"},{"type":"text","value":".","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"NMGm2R7xgi"}],"key":"VHvmfEcsxr"},{"type":"paragraph","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"Due to the complexity of UMA and training a multi-architecture, multi-dataset, multi-task model, we leverage ","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"eA9RGrKLP5"},{"type":"link","url":"https://hydra.cc/docs/tutorials/basic/your_first_app/config_groups/","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"config groups","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"LMz400LrOT"}],"urlSource":"https://hydra.cc/docs/tutorials/basic/your_first_app/config_groups/","key":"ptQmM5fzzc"},{"type":"text","value":" syntax in Hydra to organize UMA training into the ","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"NdkOipUsHP"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/tree/main/configs/uma/training_release","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"following sections","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"NZp5XX2SDx"}],"urlSource":"https://github.com/facebookresearch/fairchem/tree/main/configs/uma/training_release","error":true,"key":"GX8OFlbRTV"},{"type":"text","value":":","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"WjRrj5sntG"}],"key":"bC5WhXFV8D"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":138,"column":1},"end":{"line":143,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"text","value":"backbone","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"UevwvjlzAN"}],"key":"AerpX7fERX"},{"type":"text","value":" - selects the specific backbone architecture (e.g., uma-sm, uma-md, uma-large)","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"v1mtPybdCI"}],"key":"bWI068yGiI"}],"key":"fCJlCb1JBx"},{"type":"listItem","spread":true,"position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"children":[{"type":"text","value":"cluster","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"key":"Q9c6BBm5BS"}],"key":"Fo5y0Lgv8r"},{"type":"text","value":" - quickly switch settings between different SLURM clusters or local environment","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"key":"RKKSDsFcqX"}],"key":"SVU1Q5Bcmr"}],"key":"WtRVFjQIzr"},{"type":"listItem","spread":true,"position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"children":[{"type":"text","value":"dataset","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"EaSBXirYBs"}],"key":"TYZ2ZzsLZj"},{"type":"text","value":" - select the dataset to train on","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"yftBxgoV54"}],"key":"e7TWnZVT2y"}],"key":"nnZpZSIlt9"},{"type":"listItem","spread":true,"position":{"start":{"line":141,"column":1},"end":{"line":141,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":141,"column":1},"end":{"line":141,"column":1}},"children":[{"type":"text","value":"element_refs","position":{"start":{"line":141,"column":1},"end":{"line":141,"column":1}},"key":"O2FZwL9yEf"}],"key":"X5SJTZNfpk"},{"type":"text","value":" - select the element references","position":{"start":{"line":141,"column":1},"end":{"line":141,"column":1}},"key":"BuK5FauaVq"}],"key":"GFcs1FkYtj"}],"key":"EMcUnNpNDS"},{"type":"listItem","spread":true,"position":{"start":{"line":142,"column":1},"end":{"line":143,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"children":[{"type":"text","value":"tasks","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"key":"QzLr9tKe8q"}],"key":"uIauwcvOUP"},{"type":"text","value":" - select the task set (e.g., for direct or conservative training)","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"key":"aH5juKhMqO"}],"key":"mAaD807dDL"}],"key":"dfJK05jUh8"}],"key":"PhT6544uka"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"TmqhCveKqE"}],"key":"ZTIsY2QVz0"},{"type":"paragraph","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"children":[{"type":"text","value":"We can switch between different combinations of configs easily this way!","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"key":"B5gk8a2CQ9"}],"key":"cIt2Ocr144"}],"key":"ByWDoWZza3"},{"type":"heading","depth":3,"position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"children":[{"type":"text","value":"Example Commands","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"key":"eyexe1TGmw"}],"identifier":"example-commands","label":"Example Commands","html_id":"example-commands","implicit":true,"key":"uYnqTwlqHj"},{"type":"paragraph","position":{"start":{"line":150,"column":1},"end":{"line":150,"column":1}},"children":[{"type":"strong","position":{"start":{"line":150,"column":1},"end":{"line":150,"column":1}},"children":[{"type":"text","value":"Get training started locally using local settings and the debug dataset:","position":{"start":{"line":150,"column":1},"end":{"line":150,"column":1}},"key":"DwO3U57MyH"}],"key":"JPY7AL2fLM"}],"key":"ZQyBt5o624"},{"type":"code","lang":"bash","value":"fairchem -c configs/uma/training_release/uma_sm_direct_pretrain.yaml cluster=h100_local dataset=uma_debug","position":{"start":{"line":152,"column":1},"end":{"line":154,"column":1}},"key":"AgbKVHu685"},{"type":"paragraph","position":{"start":{"line":156,"column":1},"end":{"line":156,"column":1}},"children":[{"type":"strong","position":{"start":{"line":156,"column":1},"end":{"line":156,"column":1}},"children":[{"type":"text","value":"Train UMA conservative with 16 nodes on SLURM:","position":{"start":{"line":156,"column":1},"end":{"line":156,"column":1}},"key":"rkwIqri5np"}],"key":"f4zRvd4X1E"}],"key":"oYdc2KiDVf"},{"type":"code","lang":"bash","value":"fairchem -c configs/uma/training_release/uma_sm_conserve_finetune.yaml cluster=h100 job.scheduler.num_nodes=16 run_name=\"uma_conserve_train\"","position":{"start":{"line":158,"column":1},"end":{"line":160,"column":1}},"key":"rHqz5KmRzG"}],"key":"Jq3n05AtTr"}],"key":"RwjALbIOrK"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"FAIRChem and Custom Datasets","url":"/ase-dataset-creation","group":"AI/ML Models & Usage"},"next":{"title":"Evaluating Pretrained Models","url":"/evaluation","group":"AI/ML Models & Usage"}}},"domain":"http://localhost:3000"}