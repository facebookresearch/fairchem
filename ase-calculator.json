{"version":3,"kind":"Notebook","sha256":"761748adc358046061c1acf39d7999234ca77c3327c70c20aceb2f641190081d","slug":"ase-calculator","location":"/core/common_tasks/ase_calculator.md","dependencies":[],"frontmatter":{"title":"Inference using ASE and Predictor Interface","kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"jupytext":{"text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.17.1"}},"content_includes_title":false,"authors":[{"nameParsed":{"literal":"FAIR Chemistry & Collaborators","given":"FAIR Chemistry &","family":"Collaborators"},"name":"FAIR Chemistry & Collaborators","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/facebookresearch/fairchem","copyright":"Meta Platforms, Inc","numbering":{"title":{"offset":2}},"source_url":"https://github.com/facebookresearch/fairchem/blob/main/docs/core/common_tasks/ase_calculator.md","edit_url":"https://github.com/facebookresearch/fairchem/edit/main/docs/core/common_tasks/ase_calculator.md","exports":[{"format":"md","filename":"ase_calculator.md","url":"/build/ase_calculator-301b750039759d669302308d8684f81b.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Inference is done using ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"seLwbSiV2c"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/mlip_unit.py#L867","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"MLIPPredictUnit","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"knKI32kThE"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/mlip_unit.py#L867","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/units/mlip_unit/mlip_unit.py","from":867,"raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/units/mlip_unit/mlip_unit.py"},"internal":false,"protocol":"github","key":"R2ZwObCvpq"},{"type":"text","value":". The ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"yzSWlLtxh4"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/calculate/ase_calculator.py#L3","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"FairchemCalculator","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"dM6FBlhcxZ"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/calculate/ase_calculator.py#L3","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/calculate/ase_calculator.py","from":3,"raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/calculate/ase_calculator.py"},"internal":false,"protocol":"github","key":"gHCV2L5ExW"},{"type":"text","value":" (an ASE calculator) is simply a convenience wrapper around the MLIPPredictUnit.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"o4zCoCM9ot"}],"key":"sbrwB3cHL5"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"jR0pKS08Vy"}],"key":"KuCx8xkPKW"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"For simple cases such as demos or education, the ASE calculator is very easy to use. For more complex cases such as running MD or batched inference, we recommend using the predictor directly for better performance.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"eH9MxzNI8u"}],"key":"HCDktBCygI"}],"key":"p65sT7XfNS"}],"key":"Mb6d3w09Z0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from __future__ import annotations\n\nfrom fairchem.core import FAIRChemCalculator, pretrained_mlip\n\npredictor = pretrained_mlip.get_predict_unit(\"uma-s-1p1\", device=\"cuda\")\ncalc = FAIRChemCalculator(predictor, task_name=\"oc20\")","key":"LNOH4OKEjg"},{"type":"outputs","id":"to_ycg6NOemIwDvY6alYn","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"checkpoints/uma-s-1p1.pt:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","content_type":"text/plain"},"application/vnd.jupyter.widget-view+json":{"content":"{\"version_major\":2,\"version_minor\":0,\"model_id\":\"57dd1a12c36140ff91bd4ca79200ed47\"}","content_type":"application/vnd.jupyter.widget-view+json"}}},"key":"OCCk22HAvZ"},{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"iso_atom_elem_refs.yaml:   0%|          | 0.00/9.00k [00:00<?, ?B/s]","content_type":"text/plain"},"application/vnd.jupyter.widget-view+json":{"content":"{\"version_major\":2,\"version_minor\":0,\"model_id\":\"38352c3b2ae04d28bc431edb16117fc6\"}","content_type":"application/vnd.jupyter.widget-view+json"}}},"key":"uLTAR4bOoY"},{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"form_elem_refs.yaml:   0%|          | 0.00/11.8k [00:00<?, ?B/s]","content_type":"text/plain"},"application/vnd.jupyter.widget-view+json":{"content":"{\"version_major\":2,\"version_minor\":0,\"model_id\":\"4d22e981ea434787a271e9ad7ca39a0e\"}","content_type":"application/vnd.jupyter.widget-view+json"}}},"key":"pKjCX3pDKb"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stderr","text":"WARNING:root:If 'dataset_list' is provided in the config, the code assumes that each dataset maps to itself. Please use 'dataset_mapping' as 'dataset_list' is deprecated and will be removed in the future.\n"},"key":"P6coZTbP78"}],"key":"ixS2TNczvD"}],"key":"CEZnIPBNyA"},{"type":"block","children":[{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Need to install fairchem-core or get UMA access or getting permissions/401 errors?","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"GmhPM2OhBx"}],"key":"pcF3s2Fcud"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Install the necessary packages using pip, uv etc","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"f1TXWxuE2F"}],"key":"WYbPCAELOa"}],"key":"qwmjrALZVq"}],"key":"rk4hX1hcXY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"! pip install fairchem-core fairchem-data-oc fairchem-applications-cattsunami","visibility":"show","key":"EUK9dUOkg9"},{"type":"outputs","id":"eFH5gUH7_iMCQ1feL69hc","children":[],"visibility":"show","key":"SyfMqsNGIv"}],"data":{"tags":["skip-execution"]},"visibility":"show","key":"Q5eEJlyADh"},{"type":"list","ordered":true,"start":2,"spread":false,"position":{"start":{"line":42,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":42,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Get access to any necessary huggingface gated models","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"qUtB9iHTlU"}],"key":"kwIXTEmI0L"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":43,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Get and login to your Huggingface account","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"Rhayn3QEhr"}],"key":"paUq2iddo4"}],"key":"ewJSxQu0lW"},{"type":"listItem","spread":true,"position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Request access to ","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"mEuY1EjZsv"},{"type":"link","url":"https://huggingface.co/facebook/UMA","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"https://​huggingface​.co​/facebook​/UMA","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"RPN4LHWY5R"}],"urlSource":"https://huggingface.co/facebook/UMA","key":"zAldQS2IM7"}],"key":"s7wxFaXvgX"}],"key":"BQER5PTVnK"},{"type":"listItem","spread":true,"position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Create a Huggingface token at ","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"CRlEDOvJHq"},{"type":"link","url":"https://huggingface.co/settings/tokens/","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"https://​huggingface​.co​/settings​/tokens/","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"qkmymZ9j4f"}],"urlSource":"https://huggingface.co/settings/tokens/","key":"y8CJCUOYYX"},{"type":"text","value":" with the permission “Permissions: Read access to contents of all public gated repos you can access”","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"SdRzsXZrjA"}],"key":"LTmORNnRhY"}],"key":"dGmj9173cp"},{"type":"listItem","spread":true,"position":{"start":{"line":46,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Add the token as an environment variable using ","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"BwrBKUTnsg"},{"type":"inlineCode","value":"huggingface-cli login","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"Wb49CUxHo3"},{"type":"text","value":" or by setting the HF_TOKEN environment variable.","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"JwE2MsYxAv"}],"key":"R7ETxapOKZ"}],"key":"zVdgKwSaLI"}],"key":"UlRW5wjPOF"}],"key":"SrVqAMcx22"}],"key":"ENozatrwmw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Login using the huggingface-cli utility\n! huggingface-cli login\n\n# alternatively,\nimport os\nos.environ['HF_TOKEN'] = 'MY_TOKEN'","visibility":"show","key":"zt94iwuX7u"},{"type":"outputs","id":"P-1ERtrUyXjvMEMPvrk0H","children":[],"visibility":"show","key":"sEtt98fjmD"}],"data":{"tags":["skip-execution"]},"visibility":"show","key":"bX6UtuzE8N"}],"class":"dropdown","key":"Y7ibh9oBYb"},{"type":"heading","depth":2,"position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"Default mode","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"l5llHpktxC"}],"identifier":"default-mode","label":"Default mode","html_id":"default-mode","implicit":true,"key":"jkqxtCHbQU"},{"type":"paragraph","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"UMA is designed for both general-purpose usage (single or batched systems) and single-system long rollout (MD simulations, relaxations, etc.). For general-purpose use, we suggest using the ","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"bUhvsxcnhZ"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/api/inference.py#L92","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"default settings","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"NardIwk7Zz"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/api/inference.py#L92","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/units/mlip_unit/api/inference.py","from":92,"raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/units/mlip_unit/api/inference.py"},"internal":false,"protocol":"github","key":"WQlAXCVsiT"},{"type":"text","value":". This is a good trade-off between accuracy, speed, and memory consumption and should suffice for most applications. In this setting, on a single 80GB H100 GPU, we expect a user should be able to compute on systems as large as 50k-100k neighbors (depending on their atomic density). Batching is also supported in this mode.","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"WLh4eajvZN"}],"key":"EcuXvOMcFi"},{"type":"heading","depth":2,"position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"text","value":"Turbo mode","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"PVH0okfoom"}],"identifier":"turbo-mode","label":"Turbo mode","html_id":"turbo-mode","implicit":true,"key":"NY3MagFTZx"},{"type":"paragraph","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"For long rollout trajectory use-cases, such as molecular dynamics (MD) or relaxations, we provide a special mode called ","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"cUV3ZDoZjk"},{"type":"strong","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"turbo","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"aOI05PUiqa"}],"key":"hvDWQHzNa1"},{"type":"text","value":", which optimizes for speed but restricts the user to using a single system where the atomic composition is held constant. Turbo mode is approximately 1.5-2x faster than default mode, depending on the situation. However, batching is not supported in this mode. It can be easily activated as shown below.","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"LtBZRMrlGI"}],"key":"VL4vumitSE"}],"key":"o31KvahKyD"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"predictor = pretrained_mlip.get_predict_unit(\n    \"uma-s-1p1\", device=\"cuda\", inference_settings=\"turbo\"\n)","key":"MfFP5seasT"},{"type":"outputs","id":"9oDW37SYuCrFWbzL228oS","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stderr","text":"WARNING:root:If 'dataset_list' is provided in the config, the code assumes that each dataset maps to itself. Please use 'dataset_mapping' as 'dataset_list' is deprecated and will be removed in the future.\n"},"key":"NTI5Z51xuq"}],"key":"I9l5nsRbud"}],"key":"sedd0qGQ3J"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"text","value":"Custom modes for advanced users","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"key":"k54jbUtr1p"}],"identifier":"custom-modes-for-advanced-users","label":"Custom modes for advanced users","html_id":"custom-modes-for-advanced-users","implicit":true,"key":"aQ71EgojRQ"},{"type":"paragraph","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"The advanced user might quickly see that ","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"ygR6grlKii"},{"type":"strong","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"default","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"ItHZmWDrS3"}],"key":"h79GJSBAGl"},{"type":"text","value":" mode and ","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"EcN4tkhdvL"},{"type":"strong","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"turbo","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"fwN4beNkbI"}],"key":"cZwP3L5MnO"},{"type":"text","value":" mode are special cases of our ","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"lyoGmS9IuA"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/api/inference.py#L47","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"inference settings api","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"CnrU0myGMz"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/main/src/fairchem/core/units/mlip_unit/api/inference.py#L47","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"main","file":"src/fairchem/core/units/mlip_unit/api/inference.py","from":47,"raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/main/src/fairchem/core/units/mlip_unit/api/inference.py"},"internal":false,"protocol":"github","key":"ldFMzJeQtx"},{"type":"text","value":". You can customize it for your application if you understand what you are doing. The following table provides more information.","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"tlNrNNJs6L"}],"key":"qESHgr43HT"},{"type":"table","position":{"start":{"line":79,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"tableRow","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"tableCell","header":true,"position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"Setting Flag","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"oLfnhytk14"}],"key":"C1vW0whGsy"},{"type":"tableCell","header":true,"position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"Description","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"qxsNKP8SaJ"}],"key":"vSMFWJZ3CE"}],"key":"d6c2grfeHd"},{"type":"tableRow","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"text","value":"tf32","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"key":"I8RlXeDLbC"}],"key":"S2eB1F8IVZ"},{"type":"tableCell","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"text","value":"enables torch ","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"key":"p2kKDCq62H"},{"type":"link","url":"https://docs.pytorch.org/docs/stable/notes/cuda.html","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"text","value":"tf32","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"key":"frhYK6aSPe"}],"urlSource":"https://docs.pytorch.org/docs/stable/notes/cuda.html","key":"CLQGvkBlL2"},{"type":"text","value":" format for matrix multiplication. This will speed up inference at a slight trade-off for precision. In our tests, it makes minimal difference to most applications. It is able to preserve equivariance, energy conservation for long rollouts. However, if you are computing higher order derivatives such as Hessians or other calculations that requires strict numerical precision, we recommend turning this off","position":{"start":{"line":81,"column":1},"end":{"line":81,"column":1}},"key":"xJAUvUoUX0"}],"key":"ZdhigaWJN9"}],"key":"wVCybSVPnI"},{"type":"tableRow","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"activation_checkpointing","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"uF14ypH77z"}],"key":"uMe2cw7csU"},{"type":"tableCell","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"this uses a custom chunked activation checkpointing algorithm and allows significant savings in memory for a small inference speed penalty. If you are predicting on systems >1000 atoms, we recommend keeping this on. However, if you want the absolute fastest inference possible for small systems, you can turn this off","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"zcxzfVSUus"}],"key":"vapHjZhdjm"}],"key":"q9wP9ZMhhw"},{"type":"tableRow","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"children":[{"type":"text","value":"merge_mole","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"yMZu91jWRm"}],"key":"B6m3mYGA7L"},{"type":"tableCell","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"children":[{"type":"text","value":"This is useful in long rollout applications where the system composition stays constant. By pre-merge the MoLE weights, we can save both memory and compute.","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"qTTDx3nHEn"}],"key":"L43RobowN8"}],"key":"wBOkYL2E4I"},{"type":"tableRow","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"text","value":"compile","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"biUR1EEl2i"}],"key":"V0TzTHXJbe"},{"type":"tableCell","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"text","value":"This uses torch.compile to significantly speed up computation. Due to the way pytorch traces the internal graph, it requires a long compile time during the first iteration and can even recompile anytime it detected a significant change in input dimensions. It is not recommended if you are computing frequently on very different atomic systems.","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"FQtp8xvQLz"}],"key":"g7nLtzgVO8"}],"key":"jSlBsaI38o"},{"type":"tableRow","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"text","value":"external_graph_gen","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"key":"gfYO0k3qgr"}],"key":"QpBKLSOsSS"},{"type":"tableCell","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"text","value":"Only use this if you want to use an external graph generator. This should be rarely used except for development","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"key":"LcGpMPW3o2"}],"key":"rQGbpFYcib"}],"key":"UmjkEPYclB"}],"key":"pyJvH7iXbG"},{"type":"paragraph","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"text","value":"For example, for an MD simulation use-case for a system of ~500 atoms, we can choose to use a custom mode like the following:","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"d7zDtptE0x"}],"key":"KgVzfnW7IK"}],"key":"T0sboN4rDT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from fairchem.core.units.mlip_unit.api.inference import InferenceSettings\n\nsettings = InferenceSettings(\n    tf32=True,\n    activation_checkpointing=False,\n    merge_mole=True,\n    compile=True,\n    external_graph_gen=False,\n    internal_graph_gen_version=2,\n)\n\npredictor = pretrained_mlip.get_predict_unit(\n    \"uma-s-1p1\", device=\"cuda\", inference_settings=settings\n)","key":"j90H8eTQRN"},{"type":"outputs","id":"Lwv6V0p6jga3g5LM47oPV","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stderr","text":"WARNING:root:If 'dataset_list' is provided in the config, the code assumes that each dataset maps to itself. Please use 'dataset_mapping' as 'dataset_list' is deprecated and will be removed in the future.\n"},"key":"RAABylU7IC"}],"key":"sw9kKN6xaL"}],"key":"Co6nVfJI3C"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"children":[{"type":"text","value":"Multi-GPU Inference","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"key":"wWADTWQq2q"}],"identifier":"multi-gpu-inference","label":"Multi-GPU Inference","html_id":"multi-gpu-inference","implicit":true,"key":"I07cMFyap8"},{"type":"paragraph","position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"children":[{"type":"text","value":"UMA supports Graph Parallel inference natively. The graph is chunked into each rank and both the forward and backwards communication is handled by the built-in graph parallel algorithm with torch distributed. Because Multi-GPU inference requires special setup of communication protocols within a node and across nodes, we leverage ","position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"key":"OBPaG3K4b6"},{"type":"link","url":"https://www.ray.io/","position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"children":[{"type":"text","value":"ray","position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"key":"o6Pne9oj8c"}],"urlSource":"https://www.ray.io/","key":"srwds4JVhh"},{"type":"text","value":" to launch Ray Actors for each GPU-rank under the hood. This allows us to seamlessly scale to any infrastructure that can run Ray.","position":{"start":{"line":108,"column":1},"end":{"line":108,"column":1}},"key":"VcfumATv1o"}],"key":"g1fSeCHyAe"},{"type":"paragraph","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"children":[{"type":"text","value":"To make things simple for the user that wants to run multi-gpu inference locally, we provide a drop-in replacement for MLIPPredictUnit, called ","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"key":"xdFiGdcLJL"},{"type":"link","url":"https://github.com/facebookresearch/fairchem/blob/85bd83535fedbc1d99eee4c12e175603ccc44ef7/src/fairchem/core/units/mlip_unit/predict.py#L415","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"children":[{"type":"text","value":"ParallelMLIPPredictUnit","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"key":"iUPL5zQQKX"}],"urlSource":"https://github.com/facebookresearch/fairchem/blob/85bd83535fedbc1d99eee4c12e175603ccc44ef7/src/fairchem/core/units/mlip_unit/predict.py#L415","data":{"kind":"file","org":"facebookresearch","repo":"fairchem","reference":"85bd83535fedbc1d99eee4c12e175603ccc44ef7","file":"src/fairchem/core/units/mlip_unit/predict.py","from":415,"raw":"https://raw.githubusercontent.com/facebookresearch/fairchem/85bd83535fedbc1d99eee4c12e175603ccc44ef7/src/fairchem/core/units/mlip_unit/predict.py"},"internal":false,"protocol":"github","key":"qP39UvVx58"}],"key":"HcwwZMsZw4"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"Qkd96Gi1Mc"}],"key":"QRlRnJcTNt"},{"type":"paragraph","position":{"start":{"line":113,"column":1},"end":{"line":113,"column":1}},"children":[{"type":"text","value":"To enable multi-GPU inference, you need to install Ray manually or through the fairchem extra dependencies option.","position":{"start":{"line":113,"column":1},"end":{"line":113,"column":1}},"key":"o0RhP5hkqD"}],"key":"xt3lIAQRvK"}],"key":"e2COr3rBbE"},{"type":"code","lang":"bash","value":"pip install fairchem-core[extras]","position":{"start":{"line":116,"column":1},"end":{"line":118,"column":1}},"key":"GlwV5zj6oG"},{"type":"paragraph","position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"children":[{"type":"text","value":"For example, we can create a predictor with 8 GPU workers in a very similar way to MLIPPredictUnit and perform an MD calculation with the ASE calculator. This mode of operation is also compatible with our LAMMPS integration.","position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"key":"nFC4mpihFB"}],"key":"OOYw33OuEL"},{"type":"code","lang":"python","value":"from ase import units\nfrom ase.md.langevin import Langevin\nfrom fairchem.core import pretrained_mlip, FAIRChemCalculator\nimport time\n\nfrom fairchem.core.datasets.common_structures import get_fcc_crystal_by_num_atoms\n\npredictor = pretrained_mlip.get_predict_unit(\n    \"uma-s-1p1\", inference_settings=\"turbo\", device=\"cuda\", workers=1\n)\ncalc = FAIRChemCalculator(predictor, task_name=\"omat\")\n\natoms = get_fcc_crystal_by_num_atoms(8000)\natoms.calc = calc\n\ndyn = Langevin(\n    atoms,\n    timestep=0.1 * units.fs,\n    temperature_K=400,\n    friction=0.001 / units.fs,\n)\n# warmup 10 steps\ndyn.run(steps=10)\nstart_time = time.time()\ndyn.attach(\n    lambda: print(\n        f\"Step: {dyn.get_number_of_steps()}, E: {atoms.get_potential_energy():.3f} eV, \"\n        f\"QPS: {dyn.get_number_of_steps()/(time.time()-start_time):.2f}\"\n    ),\n    interval=1,\n)\ndyn.run(steps=1000)","position":{"start":{"line":122,"column":1},"end":{"line":155,"column":1}},"key":"DFrpbCGqly"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"mfOs6DaKI5"}],"key":"nDshdnksty"},{"type":"paragraph","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"children":[{"type":"text","value":"This will automatically create a Ray server on your local machine and use a local client to connect to it. If you have set up a Ray cluster, you can leverage it to run parallel inference on as many nodes as you like.","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"wyMczrBEl8"}],"key":"XXYSwovPp9"}],"key":"HWYuEurFh9"}],"key":"PYCWyf3hj5"}],"key":"SqFFhvkN2g"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Common Tasks","url":"/summary","group":"AI/ML Models & Usage"},"next":{"title":"LAMMPS Integration","url":"/lammps","group":"AI/ML Models & Usage"}}},"domain":"http://localhost:3000"}