{"version":3,"kind":"Article","sha256":"2bb89341232a28d7ff2b1aa4b922ab23a7b54c100dc7363a13f0caae042b012d","slug":"inference-batcher","location":"/core/common_tasks/inference_batcher.md","dependencies":[],"frontmatter":{"title":"Batched Atomic Simulations with InferenceBatcher","content_includes_title":false,"authors":[{"nameParsed":{"literal":"FAIR Chemistry & Collaborators","given":"FAIR Chemistry &","family":"Collaborators"},"name":"FAIR Chemistry & Collaborators","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/facebookresearch/fairchem","copyright":"Meta Platforms, Inc","numbering":{"title":{"offset":2}},"source_url":"https://github.com/facebookresearch/fairchem/blob/main/docs/core/common_tasks/inference_batcher.md","edit_url":"https://github.com/facebookresearch/fairchem/edit/main/docs/core/common_tasks/inference_batcher.md","exports":[{"format":"md","filename":"inference_batcher.md","url":"/build/inference_batcher-460790629643f349834160b1bf9215fc.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Need to install fairchem-core or get UMA access or getting permissions/401 errors?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"kQnQxd4BCg"}],"key":"x8xGkzUqA1"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Install the necessary packages using pip, uv etc","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Aq6UgAhFoP"}],"key":"Rm8e4rUacB"}],"key":"OqWoowKZFJ"}],"key":"k7n4hYJTAi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"! pip install fairchem-core fairchem-data-oc fairchem-applications-cattsunami","visibility":"show","key":"ysX5QfR8uS"},{"type":"outputs","id":"gGhqWwUsaxKUm9dYdW99z","children":[],"visibility":"show","key":"LBRh9wFz39"}],"data":{"tags":["skip-execution"]},"visibility":"show","key":"cnmqBz3IQp"},{"type":"list","ordered":true,"start":2,"spread":false,"position":{"start":{"line":14,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Get access to any necessary huggingface gated models","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"QGDHX3UCxE"}],"key":"u8p0OFOQzF"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":15,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Get and login to your Huggingface account","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"NbMQMb3UVc"}],"key":"af8LXPpErW"}],"key":"K2xq5Sx69n"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Request access to ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"eAnNyJ7edJ"},{"type":"link","url":"https://huggingface.co/facebook/UMA","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"https://​huggingface​.co​/facebook​/UMA","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"GZ0csecxgh"}],"urlSource":"https://huggingface.co/facebook/UMA","key":"hRNh57vizs"}],"key":"mXQ4znRtsY"}],"key":"q73UT2YzgA"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Create a Huggingface token at ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"P6GpZ2YqKZ"},{"type":"link","url":"https://huggingface.co/settings/tokens/","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"https://​huggingface​.co​/settings​/tokens/","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"mpb8L31tWd"}],"urlSource":"https://huggingface.co/settings/tokens/","key":"RqPNBpvXSr"},{"type":"text","value":" with the permission “Permissions: Read access to contents of all public gated repos you can access”","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"KAkv4ATw7k"}],"key":"WwSR3IrbLH"}],"key":"Zwt3q2oQlf"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Add the token as an environment variable using ","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"jK6W9I8T4q"},{"type":"inlineCode","value":"huggingface-cli login","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"pdn01LZpXu"},{"type":"text","value":" or by setting the HF_TOKEN environment variable.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"bFU0yP1ZQA"}],"key":"atXgLmx8UP"}],"key":"VAQmwwv7XD"}],"key":"xG2EjPM2MB"}],"key":"WNVxFmQeZ4"}],"key":"Av774tL8bG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Login using the huggingface-cli utility\n! huggingface-cli login\n\n# alternatively,\nimport os\nos.environ['HF_TOKEN'] = 'MY_TOKEN'","visibility":"show","key":"dBTPVQap9z"},{"type":"outputs","id":"bPpRxBLxyJVnJ-a_6nmjb","children":[],"visibility":"show","key":"uJSt4HbJUD"}],"data":{"tags":["skip-execution"]},"visibility":"show","key":"lcn4HRU9rq"}],"class":"dropdown","key":"XmCHKjX6zh"},{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Warning","key":"h0B3hnbQNv"}],"key":"ymJgezKfIg"},{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"vq9WibpcKg"},{"type":"inlineCode","value":"InferenceBatcher","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"je3cemx3VU"},{"type":"text","value":" class and underlying concurrent batching implementations are experimental and under current development. The API may change. If you have suggestions for improvements, please open an issue or submit a pull request.","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"Y4ARh6Erg4"}],"key":"d2ntaxbgLM"}],"key":"aamESBYvF6"},{"type":"paragraph","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"When running many independent ASE calculations (relaxations, molecular dynamics, etc.) on small to medium-sized systems, you can significantly improve GPU utilization by batching model inference calls together. The ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"be4b6xwfw1"},{"type":"inlineCode","value":"InferenceBatcher","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"GRN1YZ1Jdp"},{"type":"text","value":" class provides a high-level API to do this with minimal code changes.","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"XdphEgihk3"}],"key":"qo4hSzuSHw"},{"type":"paragraph","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"The key idea is simple: instead of running each simulation sequentially, ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"XuoxVrCVUZ"},{"type":"inlineCode","value":"InferenceBatcher","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"fbIr83IxCg"},{"type":"text","value":" collects inference requests from multiple concurrent simulations and batches them together for more efficient GPU computation.","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"QOvE6HwCNz"}],"key":"kGCb2qMIX2"},{"type":"heading","depth":2,"position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Basic Setup","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"zREZPXWBQL"}],"identifier":"basic-setup","label":"Basic Setup","html_id":"basic-setup","implicit":true,"key":"bJo4zVCCON"},{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"To use ","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"JvCGxRnnBk"},{"type":"inlineCode","value":"InferenceBatcher","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"P2YMzgLHLm"},{"type":"text","value":", you need to:","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"KJOodDm2Ew"}],"key":"pWNtjdbTzX"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":45,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Create a predict unit as usual","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"bUEDVZMECD"}],"key":"AWELcXYR9W"}],"key":"sMvMc5WKZP"},{"type":"listItem","spread":true,"position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Wrap it with ","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"XCXverqwwL"},{"type":"inlineCode","value":"InferenceBatcher","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"gYvOxGKLcY"}],"key":"kxi71MqrZ6"}],"key":"JIUu1B8qz7"},{"type":"listItem","spread":true,"position":{"start":{"line":47,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Use ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"HQ2EncUkRR"},{"type":"inlineCode","value":"batcher.batch_predict_unit","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"ug8vpixVbh"},{"type":"text","value":" instead of the original predict unit in your simulation functions","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"iqq0TF8zrS"}],"key":"l4PA5laWRC"}],"key":"t5zjLyIG4x"}],"key":"d2lvBCbYxc"},{"type":"code","lang":"python","value":"from fairchem.core import pretrained_mlip\nfrom fairchem.core.calculate import FAIRChemCalculator, InferenceBatcher\n\n# Create a predict unit\npredict_unit = pretrained_mlip.get_predict_unit(\"uma-s-1p1\")\n\n# Wrap it with InferenceBatcher\nbatcher = InferenceBatcher(\n    predict_unit, concurrency_backend_options=dict(max_workers=32)\n)","position":{"start":{"line":49,"column":1},"end":{"line":60,"column":1}},"key":"A9NKzOplbJ"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"qp8mJmPINj"}],"key":"kKyJJ49zyQ"},{"type":"paragraph","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"B62ICnG0qg"},{"type":"inlineCode","value":"max_workers","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"DtEf2BAri0"},{"type":"text","value":" parameter controls how many concurrent simulations can run concurrently. Adjust this based on your system’s memory and the size of your structures.","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"Dd49VCjBJa"}],"key":"mXdDGr0gs2"}],"key":"rbs4UaYxgt"},{"type":"heading","depth":2,"position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"Writing Simulation Functions","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"BEhwB3XYl5"}],"identifier":"writing-simulation-functions","label":"Writing Simulation Functions","html_id":"writing-simulation-functions","implicit":true,"key":"sBurqFGJLL"},{"type":"paragraph","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"text","value":"The only requirement for using ","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"JiSAX7OVsh"},{"type":"inlineCode","value":"InferenceBatcher","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"XY99lwItPq"},{"type":"text","value":" is to write your simulation logic as a function that takes an ","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"nztky3wV8j"},{"type":"inlineCode","value":"Atoms","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"XXNPE5oa8X"},{"type":"text","value":" object and a predict unit as arguments:","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"HqOSwQnqwf"}],"key":"vSXng2AdOQ"},{"type":"code","lang":"python","value":"from ase.build import bulk\nfrom ase.filters import FrechetCellFilter\nfrom ase.optimize import LBFGS\n\n\ndef run_relaxation(atoms, predict_unit):\n    \"\"\"Run a structure relaxation and return the final energy.\"\"\"\n    calc = FAIRChemCalculator(predict_unit, task_name=\"omat\")\n    atoms.calc = calc\n    opt = LBFGS(FrechetCellFilter(atoms), logfile=None)\n    opt.run(fmax=0.02, steps=100)\n    return atoms.get_potential_energy()","position":{"start":{"line":70,"column":1},"end":{"line":83,"column":1}},"key":"iyvQdQqhyP"},{"type":"heading","depth":2,"position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"text","value":"Running Batched Relaxations","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"key":"Vy5koGQjMq"}],"identifier":"running-batched-relaxations","label":"Running Batched Relaxations","html_id":"running-batched-relaxations","implicit":true,"key":"xfDCxbvHDd"},{"type":"paragraph","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"text","value":"Once you have your simulation function, you can run it in batched mode using the executor’s ","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"Id8kL9HvP4"},{"type":"inlineCode","value":"map","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"glbzwCpdBz"},{"type":"text","value":" or ","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"yPholyVyu5"},{"type":"inlineCode","value":"submit","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"pe46ruQyJF"},{"type":"text","value":" methods:","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"ZnOgKzKT7C"}],"key":"vJbviAR87O"},{"type":"heading","depth":3,"position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"text","value":"Using ","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"mPVlOvu7HR"},{"type":"inlineCode","value":"executor.map","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"ZAifpscHcM"}],"identifier":"using-executor-map","label":"Using executor.map","html_id":"using-executor-map","implicit":true,"key":"ytMCwbZUTH"},{"type":"code","lang":"python","value":"from functools import partial\n\n# Create a list of structures to relax\nprim_atoms = [\n    bulk(\"Cu\"),\n    bulk(\"MgO\", \"rocksalt\", a=4.2),\n    bulk(\"Si\", \"diamond\", a=5.43),\n    bulk(\"NaCl\", \"rocksalt\", a=3.8),\n]\n\natoms_list = [make_supercell(atoms, 3 * np.identity(3)) for atoms in prim_atoms]\n\nfor atoms in atoms_list:\n    atoms.rattle(0.1)\n\n# Create a partial function with the batch predict unit\nrun_relaxation_batched = partial(\n    run_relaxation, predict_unit=batcher.batch_predict_unit\n)\n\n# Run all relaxations in parallel with batched inference\nrelaxed_energies = list(batcher.executor.map(run_relaxation_batched, atoms_list))","position":{"start":{"line":91,"column":1},"end":{"line":114,"column":1}},"key":"mQbhdW2G7U"},{"type":"heading","depth":3,"position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"children":[{"type":"text","value":"Using ","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"le4DchfDOz"},{"type":"inlineCode","value":"executor.submit","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"X0zA7zWibj"},{"type":"text","value":" for more control","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"lYYzEk6NA2"}],"identifier":"using-executor-submit-for-more-control","label":"Using executor.submit for more control","html_id":"using-executor-submit-for-more-control","implicit":true,"key":"CKo5NpUbTQ"},{"type":"paragraph","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"children":[{"type":"text","value":"If you need more control over the execution or want to process results as they complete:","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"key":"NS4XHGx9Jh"}],"key":"SuDbkHrbbh"},{"type":"code","lang":"python","value":"# Create a new list of structures to relax\natoms_list = [make_supercell(atoms, 3 * np.identity(3)) for atoms in prim_atoms]\n\nfor atoms in atoms_list:\n    atoms.rattle(0.1)\n\n# Submit all jobs\nfutures = [\n    batcher.executor.submit(run_relaxation, atoms, batcher.batch_predict_unit)\n    for atoms in atoms_list\n]\n\n# Collect results\nrelaxed_energies = [future.result() for future in futures]","position":{"start":{"line":120,"column":1},"end":{"line":135,"column":1}},"key":"iMvwJEjfFV"},{"type":"heading","depth":2,"position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"children":[{"type":"text","value":"Running Batched Molecular Dynamics","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"mW1BTfqRFy"}],"identifier":"running-batched-molecular-dynamics","label":"Running Batched Molecular Dynamics","html_id":"running-batched-molecular-dynamics","implicit":true,"key":"hKNrD3cVm7"},{"type":"paragraph","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"children":[{"type":"text","value":"The same pattern works for molecular dynamics simulations:","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"key":"omEovB0LNd"}],"key":"ZOnH3XEPfx"},{"type":"code","lang":"python","value":"from ase import units\nfrom ase.md.langevin import Langevin\nfrom ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n\n\ndef run_nvt_md(atoms, predict_unit, temperature, traj_fname):\n    \"\"\"Run NVT molecular dynamics simulation.\"\"\"\n    calc = FAIRChemCalculator(predict_unit, task_name=\"omat\")\n    atoms.calc = calc\n    MaxwellBoltzmannDistribution(atoms, temperature, force_temp=True)\n    dyn = Langevin(\n        atoms,\n        timestep=2 * units.fs,\n        temperature_K=temperature,\n        friction=0.1,\n        trajectory=traj_fname,\n        loginterval=5,\n    )\n    dyn.run(100)\n\n\n# Run batched MD simulations\nrun_md_batched = partial(\n    run_nvt_md, predict_unit=batcher.batch_predict_unit, temperature=300\n)\n\nfutures = [\n    batcher.executor.submit(run_md_batched, atoms, traj_fname=f\"traj_{i}.traj\")\n    for i, atoms in enumerate(atoms_list)\n]\n\n# Wait for all simulations to complete\n[future.result() for future in futures]","position":{"start":{"line":141,"column":1},"end":{"line":175,"column":1}},"key":"piNIVjxMk7"},{"type":"heading","depth":2,"position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"children":[{"type":"text","value":"When to Use InferenceBatcher","position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"key":"Ba3L7F1OYG"}],"identifier":"when-to-use-inferencebatcher","label":"When to Use InferenceBatcher","html_id":"when-to-use-inferencebatcher","implicit":true,"key":"La28uKmgbM"},{"type":"paragraph","position":{"start":{"line":179,"column":1},"end":{"line":179,"column":1}},"children":[{"type":"inlineCode","value":"InferenceBatcher","position":{"start":{"line":179,"column":1},"end":{"line":179,"column":1}},"key":"q5BwA2MBij"},{"type":"text","value":" is most beneficial when:","position":{"start":{"line":179,"column":1},"end":{"line":179,"column":1}},"key":"GiwRc7JfaQ"}],"key":"Hdk3bZssth"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":181,"column":1},"end":{"line":184,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":181,"column":1},"end":{"line":181,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Running many independent simulations on small to medium-sized systems","position":{"start":{"line":181,"column":1},"end":{"line":181,"column":1}},"key":"yk9H1FR6l8"}],"key":"G3YK4DmiNl"}],"key":"LzTtITHscJ"},{"type":"listItem","spread":true,"position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"GPU utilization is low with serial execution","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"key":"K3a5OvTyrx"}],"key":"STj9idx0DK"}],"key":"P8Yg1Yzary"},{"type":"listItem","spread":true,"position":{"start":{"line":183,"column":1},"end":{"line":184,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Each individual simulation has many inference steps (relaxations, MD)","position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"key":"RoRTjj6nCT"}],"key":"RFzqxhQU9Z"}],"key":"QbSsf0uKKS"}],"key":"G3x3xpZSVy"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"P7PztxBCR3"}],"key":"EyUZAr2dVP"},{"type":"paragraph","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"children":[{"type":"text","value":"When running batch inference over static structures, consider using the ","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"jaZDHmGW1g"},{"type":"link","url":"/batch-inference","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"children":[{"type":"text","value":"batch inference approach","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"YX96zRWcMP"}],"urlSource":"batch_inference.md","dataUrl":"/batch-inference.json","internal":true,"protocol":"file","key":"ZOGqE4ziHL"},{"type":"text","value":" with ","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"ukuxo4idqC"},{"type":"inlineCode","value":"AtomicData","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"RvnopCBGGG"},{"type":"text","value":" directly instead. For single large systems, consider using the ","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"DncyFCxz8E"},{"type":"inlineCode","value":"MLIPParallelPredictUnit","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"auBsVSYb9y"},{"type":"text","value":" for graph parallel inference.","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"vX5r4bU1vm"}],"key":"HTjbXfNBvh"}],"key":"NpEocx9Ov8"}],"key":"lFTlIvVsBD"}],"key":"DprvxdfGx5"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Batch Inference with UMA Models","url":"/batch-inference","group":"AI/ML Models & Usage"},"next":{"title":"FAIRChem and Custom Datasets","url":"/ase-dataset-creation","group":"AI/ML Models & Usage"}}},"domain":"http://localhost:3000"}