{"version":3,"kind":"Notebook","sha256":"d26c9a80909a28ff5993a53fcf762aa8f8d796654c625fcdb0ce10227f0bc12a","slug":"fine-tuning","location":"/core/common_tasks/fine_tuning.md","dependencies":[],"frontmatter":{"title":"Fine-tuning","kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"jupytext":{"text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.17.1"}},"content_includes_title":false,"authors":[{"nameParsed":{"literal":"FAIR Chemistry & Collaborators","given":"FAIR Chemistry &","family":"Collaborators"},"name":"FAIR Chemistry & Collaborators","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/facebookresearch/fairchem","copyright":"Meta Platforms, Inc","numbering":{"title":{"offset":2}},"source_url":"https://github.com/facebookresearch/fairchem/blob/main/docs/core/common_tasks/fine_tuning.md","edit_url":"https://github.com/facebookresearch/fairchem/edit/main/docs/core/common_tasks/fine_tuning.md","exports":[{"format":"md","filename":"fine_tuning.md","url":"/build/fine_tuning-a0ef1b149cc3ac7887b084d268a68499.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"This repo provides a number of scripts to quickly fine-tune a model using a custom ASE LMDB dataset. These scripts are merely for convenience and fine-tuning uses the exact same tooling and infrastructure as our standard training (see Training section). Training in the fairchem repo uses the fairchem CLI tool and configs are in ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"Tx5lraEysl"},{"type":"link","url":"https://hydra.cc/","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Hydra yaml","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"gynATB5RpR"}],"urlSource":"https://hydra.cc/","key":"LG2ln3XFya"},{"type":"text","value":" format.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"ZDNvzmH0OY"}],"key":"kT3Pv33S5U"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"Zl1oBgzqzZ"}],"key":"ZVs4YRrq4j"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Training datasets must be in the ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"l5wrSNQszo"},{"type":"link","url":"https://wiki.fysik.dtu.dk/ase/ase/db/db.html#ase.db.core.connect","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"ASE-lmdb format","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"ddhCsAlIW1"}],"urlSource":"https://wiki.fysik.dtu.dk/ase/ase/db/db.html#ase.db.core.connect","key":"Sv2QLqrnX5"},{"type":"text","value":". For UMA models, we provide a simple script to help generate ASE-lmdb datasets from a variety of input formats (CIFs, traj, extxyz, etc.) as well as a fine-tuning YAML config that can be directly used for fine-tuning.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"JchkwFxSmR"}],"key":"OIu690HoWx"}],"key":"yOfOZ03v2e"},{"type":"heading","depth":2,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Generating Training/Fine-tuning Datasets","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"Y7ruJekbQZ"}],"identifier":"generating-training-fine-tuning-datasets","label":"Generating Training/Fine-tuning Datasets","html_id":"generating-training-fine-tuning-datasets","implicit":true,"key":"SUo1QgcIdE"},{"type":"paragraph","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"First we need to generate a dataset in the aselmdb format for fine-tuning.","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"ufMtImYnsM"}],"key":"VWYQXWH5OF"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"zzbOLmNmOk"}],"key":"jUrMFCiMqm"},{"type":"paragraph","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"The only requirement is that you have input files that can be read as ASE atoms objects by the ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"DWGln0fGfO"},{"type":"inlineCode","value":"ase.io.read","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"PyVRmzgItW"},{"type":"text","value":" routine and that they contain energy (forces, stress) in the correct format. For concrete examples, refer to the test at ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"JrNyPYGX5v"},{"type":"inlineCode","value":"tests/core/scripts/test_create_finetune_dataset.py","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"I9RUIRRP1P"},{"type":"text","value":".","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"df4hIFK9qI"}],"key":"Wzx84GWMfa"}],"key":"HUulUiUpF5"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"First you should checkout the fairchem repo and install it to access the scripts","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"LezQi1S14m"}],"key":"uzHztdKHhP"}],"key":"VgOJn5LqPU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"git clone git@github.com:facebookresearch/fairchem.git\n\npip install -e fairchem/src/packages/fairchem-core[dev]","visibility":"show","key":"xi8KdUa8h5"},{"type":"outputs","id":"vH91QioYjCE23z2KE0-I0","children":[],"visibility":"show","key":"RobNxuejqm"}],"data":{"tags":["skip-execution"]},"visibility":"show","key":"SQoYi0vrJN"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Run this script to create the aselmdbs as well as a set of templated yamls for finetuning, we will use a few dummy structures for demonstration purposes","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"KkvnNgSTZu"}],"key":"pRfrvrw1W6"}],"key":"WNJbUUalta"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import os\nos.chdir('../../../../fairchem')\n! python src/fairchem/core/scripts/create_uma_finetune_dataset.py --train-dir docs/core/common_tasks/finetune_assets/train/ --val-dir docs/core/common_tasks/finetune_assets/val --output-dir /tmp/bulk --uma-task=omat --regression-task e","key":"HoNfYgQs0u"},{"type":"outputs","id":"GvGxu4_NEXXna7sMJgWlc","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\r  0%|                                                     | 0/1 [00:00<?, ?it/s]\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\r\n\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 114.36it/s]\r\n\r100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 73.98it/s]\r\n"},"key":"gFXXbVbncM"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rComputing normalizer values.:   0%|                       | 0/2 [00:00<?, ?it/s]\rComputing normalizer values.: 100%|████████████| 2/2 [00:00<00:00, 26214.40it/s]\r\n"},"key":"Z8yQQzdFnx"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r  0%|                                                     | 0/1 [00:00<?, ?it/s]\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r\n\r\n\r\n\r\n\r0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\r0it [00:00, ?it/s]\r\n\r100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 98.94it/s]\r\n\r100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 82.39it/s]\r\n"},"key":"J6ZcjfMeZA"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:Generated dataset and data config yaml in /tmp/bulk\r\nINFO:root:To run finetuning, run fairchem -c /tmp/bulk/uma_sm_finetune_template.yaml\r\n"},"key":"v1zf9hyHdU"}],"key":"S5I1g4FxDY"}],"key":"QOmS8kGgJ3"},{"type":"block","children":[{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Warning","key":"sCxvkkXIRq"}],"key":"a0U3n98p3j"},{"type":"paragraph","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"strong","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Task Selection:","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"dtCPzrrivO"}],"key":"JMhN7RB2x3"},{"type":"text","value":" The ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"XBo7khdeDM"},{"type":"inlineCode","value":"uma-task","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"B7632nzuHy"},{"type":"text","value":" can be one of: ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"cmRvM67dVn"},{"type":"inlineCode","value":"omol","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"GSKMJY7hWo"},{"type":"text","value":", ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"TfrTKU8BJJ"},{"type":"inlineCode","value":"odac","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"foxcrGLW1y"},{"type":"text","value":", ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"g51CqP0fCh"},{"type":"inlineCode","value":"oc20","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"JemtJDgzKO"},{"type":"text","value":", ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"LAbGrjiwl4"},{"type":"inlineCode","value":"omat","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"ynnc5GjbLA"},{"type":"text","value":", ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"jqW44Kt0N7"},{"type":"inlineCode","value":"omc","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"amvBsK3HA1"},{"type":"text","value":". While UMA was trained in a multi-task fashion, we ONLY support fine-tuning on a single UMA task at a time. Multi-task training can become very complicated! Feel free to contact us on GitHub if you have a special use-case for multi-task fine-tuning, or refer to the training configs in ","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"cIULBfgElv"},{"type":"inlineCode","value":"/training_release","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"qQH69XZtBj"},{"type":"text","value":" to mimic the original UMA training configs.","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"XxzM264tPL"}],"key":"MmuMq1TL1w"}],"key":"wn9edBkahk"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Regression Task Options","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"TCK691ZSeY"}],"key":"iRVpId2kCs"},{"type":"paragraph","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"QDcMclu5WZ"},{"type":"inlineCode","value":"regression-task","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"mfvYOGMwWD"},{"type":"text","value":" can be one of:","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"KBvOnwWp08"}],"key":"VQUYhPNsUC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":54,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"e","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"AREwupJTg1"}],"key":"m93S7moZYi"},{"type":"text","value":": Energy only","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"ziKXseeqpA"}],"key":"mcM8tDjvlV"}],"key":"wsDyCIZvBO"},{"type":"listItem","spread":true,"position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"ef","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"lpiMFHq9qp"}],"key":"oRaIArC0MG"},{"type":"text","value":": Energy + forces","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"jQ8WcreAYK"}],"key":"Sc2aYtfqt0"}],"key":"H6VWOtLsJL"},{"type":"listItem","spread":true,"position":{"start":{"line":56,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"efs","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"pcUjwt8xic"}],"key":"CTKhKLvRKE"},{"type":"text","value":": Energy + forces + stress","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"xDnnNKW40G"}],"key":"IvfhyPRASC"}],"key":"Ihvas4Zwu3"}],"key":"bHr6IO8siz"},{"type":"paragraph","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"Choose based on the data you have available in the ASE db. For example, some aperiodic DFT codes only support energy/forces and not gradients, and some very fancy codes like QMC only produce energies.","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"dwpyKHwYD0"}],"key":"vB2448J6J3"},{"type":"paragraph","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"strong","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"Note:","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"p7z8uH2GoE"}],"key":"yxlG2ACnud"},{"type":"text","value":" Even if you train on just energy or energy/forces, all gradients (forces/stresses) will be computable via the model gradients.","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"dgpp8SCBML"}],"key":"kT3R8IHnVi"}],"class":"dropdown","key":"ZqnI5ZAnMr"},{"type":"paragraph","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"This will generate a folder of LMDBs and a ","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"A5pjmKrTY1"},{"type":"inlineCode","value":"uma_sm_finetune_template.yaml","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"GYYXD8zSKP"},{"type":"text","value":" that you can run directly with the fairchem CLI to start training.","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"BxKpAI4boW"}],"key":"iLXfV9mQKV"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"vUIvtxQWCk"}],"key":"Avj9CX3PmD"},{"type":"paragraph","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"If you want to only create the ASE LMDBs, you can use ","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"tD8uHhfAVB"},{"type":"inlineCode","value":"src/fairchem/core/scripts/create_finetune_dataset.py","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"y5ESwMWeFC"},{"type":"text","value":" which is called by ","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"yVOMYmDcqV"},{"type":"inlineCode","value":"create_uma_finetune_dataset.py","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"nWOgGFWuWc"},{"type":"text","value":".","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"bklsisz5fz"}],"key":"SUDHDuHV3s"}],"key":"cVNHlvL6C3"},{"type":"heading","depth":2,"position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"text","value":"Model Fine-tuning (Default Settings)","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"Z5vOq5stSs"}],"identifier":"model-fine-tuning-default-settings","label":"Model Fine-tuning (Default Settings)","html_id":"model-fine-tuning-default-settings","implicit":true,"key":"CjWLrU7xbR"},{"type":"paragraph","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"text","value":"The previous step should have generated some YAML files to get you started on fine-tuning. You can simply run this with the ","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"Kg5RJ7BkVb"},{"type":"inlineCode","value":"fairchem","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"UhzoNwmEne"},{"type":"text","value":" CLI. The default is configured to run locally on 1 GPU.","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"Z0gBU2tsn1"}],"key":"ttWZRL2hDs"}],"key":"ZaLIgpjabf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"! fairchem -c /tmp/bulk/uma_sm_finetune_template.yaml","visibility":"show","key":"D8VqJNLHOQ"},{"type":"outputs","id":"_MdWaYee_3PvGKKvQghyh","children":[],"visibility":"show","key":"arpvypA7p6"}],"data":{"tags":["skip-execution"]},"visibility":"show","key":"ouNBIwKCvL"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"children":[{"type":"text","value":"Advanced Configuration","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"jGw395crin"}],"identifier":"advanced-configuration","label":"Advanced Configuration","html_id":"advanced-configuration","implicit":true,"key":"jMFEqPNInL"},{"type":"paragraph","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"children":[{"type":"text","value":"The scripts provide a simple way to get started on fine-tuning, but likely for your own use cases you will need to modify the parameters. The configuration uses ","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"pvGat3U51V"},{"type":"link","url":"https://hydra.cc/","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"children":[{"type":"text","value":"Hydra-style YAMLs","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"XK8UbaQO8d"}],"urlSource":"https://hydra.cc/","key":"HmLehOwnT5"},{"type":"text","value":".","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"RJgJ2Yu6ys"}],"key":"X423g1tWf9"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"Gd7pRTkkBv"}],"key":"C5VcLtXtOe"},{"type":"paragraph","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"children":[{"type":"text","value":"To modify the generated YAMLs, you can either edit the files directly or use ","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"sWbjNR0Wzf"},{"type":"link","url":"https://hydra.cc/docs/advanced/override_grammar/basic/","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"children":[{"type":"text","value":"Hydra override notation","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"vpjRy39eW3"}],"urlSource":"https://hydra.cc/docs/advanced/override_grammar/basic/","key":"v6MYTBWj03"},{"type":"text","value":". Changing parameters on the command line is very simple:","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"s2x62H9RyH"}],"key":"qFW3qcCJLW"}],"key":"DI7kYg8BDA"}],"key":"Fqd3vg14ao"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"! fairchem -c /tmp/bulk/uma_sm_finetune_template.yaml epochs=2 lr=2e-4 job.run_dir=/tmp/finetune_dir +job.timestamp_id=some_id","key":"qgnS0Q8lsz"},{"type":"outputs","id":"Gt2tK6uGjdtfQRCt_WRZr","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:saved canonical config to /tmp/finetune_dir/some_id/canonical_config.yaml\r\nINFO:root:Running fairchemv2 cli with {'job': {'run_name': 'uma_finetune', 'timestamp_id': 'some_id', 'run_dir': '/tmp/finetune_dir', 'device_type': <DeviceType.CUDA: 'cuda'>, 'debug': True, 'scheduler': {'mode': <SchedulerType.LOCAL: 'local'>, 'distributed_init_method': <DistributedInitMethod.TCP: 'tcp'>, 'ranks_per_node': 1, 'num_nodes': 1, 'num_array_jobs': 1, 'slurm': {'mem_gb': 80, 'timeout_hr': 168, 'cpus_per_task': 8, 'partition': None, 'qos': None, 'account': None, 'additional_parameters': None}, 'use_ray': False, 'ray_cluster': {'head_gpus': 0}}, 'logger': {'_target_': 'fairchem.core.common.logger.WandBSingletonLogger.init_wandb', '_partial_': True, 'entity': 'example', 'project': 'uma_finetune'}, 'seed': 0, 'deterministic': False, 'runner_state_path': None, 'metadata': {'commit': 'core:None,experimental:NA', 'log_dir': '/tmp/finetune_dir/some_id/logs', 'checkpoint_dir': '/tmp/finetune_dir/some_id/checkpoints', 'results_dir': '/tmp/finetune_dir/some_id/results', 'config_path': '/tmp/finetune_dir/some_id/canonical_config.yaml', 'preemption_checkpoint_dir': '/tmp/finetune_dir/some_id/checkpoints/preemption_state', 'cluster_name': 'github', 'array_job_num': 0, 'slurm_env': {'job_id': None, 'raw_job_id': None, 'array_job_id': None, 'array_task_id': None, 'restart_count': None}}, 'graph_parallel_group_size': None, 'recursive_instantiate_runner': True}, 'runner': {'_target_': 'fairchem.core.components.train.train_runner.TrainEvalRunner', 'train_dataloader': {'_target_': 'fairchem.core.components.common.dataloader_builder.get_dataloader', 'dataset': {'_target_': 'fairchem.core.datasets.mt_concat_dataset.create_concat_dataset', 'dataset_configs': {'omat': {'splits': {'train': {'src': '/tmp/bulk/train'}}, 'format': 'ase_db', 'transforms': {'common_transform': {'dataset_name': 'omat'}, 'stress_reshape_transform': {'dataset_name': 'omat'}}}}, 'combined_dataset_config': {'sampling': {'type': 'temperature', 'temperature': 1.0}}}, 'batch_sampler_fn': {'_target_': 'fairchem.core.common.data_parallel.BalancedBatchSampler', '_partial_': True, 'batch_size': 2, 'shuffle': True, 'seed': 0}, 'num_workers': 0, 'collate_fn': {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter', 'tasks': [{'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'energy', 'level': 'system', 'property': 'energy', 'loss_fn': {'_target_': 'fairchem.core.modules.loss.DDPMTLoss', 'loss_fn': {'_target_': 'fairchem.core.modules.loss.PerAtomMAELoss'}, 'coefficient': 20}, 'out_spec': {'dim': [1], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'element_references': {'_target_': 'fairchem.core.modules.normalization.element_references.ElementReferences', 'element_references': {'_target_': 'torch.DoubleTensor', '_args_': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.082805460035017, 0.0, 0.0, 0.0, -3.256404920200298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]}}, 'datasets': ['omat'], 'metrics': ['mae', 'per_atom_mae']}, {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'forces', 'level': 'atom', 'property': 'forces', 'out_spec': {'dim': [3], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'datasets': ['omat'], 'inference_only': True}, {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'stress', 'level': 'system', 'property': 'stress', 'out_spec': {'dim': [1, 9], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'datasets': ['omat'], 'inference_only': True}]}}, 'eval_dataloader': {'_target_': 'fairchem.core.components.common.dataloader_builder.get_dataloader', 'dataset': {'_target_': 'fairchem.core.datasets.mt_concat_dataset.create_concat_dataset', 'dataset_configs': {'omat': {'splits': {'val': {'src': '/tmp/bulk/val'}}, 'format': 'ase_db', 'transforms': {'common_transform': {'dataset_name': 'omat'}, 'stress_reshape_transform': {'dataset_name': 'omat'}}}}, 'combined_dataset_config': {'sampling': {'type': 'temperature', 'temperature': 1.0}}}, 'batch_sampler_fn': {'_target_': 'fairchem.core.common.data_parallel.BalancedBatchSampler', '_partial_': True, 'batch_size': 2, 'shuffle': False, 'seed': 0}, 'num_workers': 0, 'collate_fn': {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter', 'tasks': [{'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'energy', 'level': 'system', 'property': 'energy', 'loss_fn': {'_target_': 'fairchem.core.modules.loss.DDPMTLoss', 'loss_fn': {'_target_': 'fairchem.core.modules.loss.PerAtomMAELoss'}, 'coefficient': 20}, 'out_spec': {'dim': [1], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'element_references': {'_target_': 'fairchem.core.modules.normalization.element_references.ElementReferences', 'element_references': {'_target_': 'torch.DoubleTensor', '_args_': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.082805460035017, 0.0, 0.0, 0.0, -3.256404920200298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]}}, 'datasets': ['omat'], 'metrics': ['mae', 'per_atom_mae']}, {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'forces', 'level': 'atom', 'property': 'forces', 'out_spec': {'dim': [3], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'datasets': ['omat'], 'inference_only': True}, {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'stress', 'level': 'system', 'property': 'stress', 'out_spec': {'dim': [1, 9], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'datasets': ['omat'], 'inference_only': True}]}}, 'train_eval_unit': {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.MLIPTrainEvalUnit', 'job_config': {'run_name': 'uma_finetune', 'timestamp_id': 'some_id', 'run_dir': '/tmp/finetune_dir', 'device_type': <DeviceType.CUDA: 'cuda'>, 'debug': True, 'scheduler': {'mode': <SchedulerType.LOCAL: 'local'>, 'distributed_init_method': <DistributedInitMethod.TCP: 'tcp'>, 'ranks_per_node': 1, 'num_nodes': 1, 'num_array_jobs': 1, 'slurm': {'mem_gb': 80, 'timeout_hr': 168, 'cpus_per_task': 8, 'partition': None, 'qos': None, 'account': None, 'additional_parameters': None}, 'use_ray': False, 'ray_cluster': {'head_gpus': 0}}, 'logger': {'_target_': 'fairchem.core.common.logger.WandBSingletonLogger.init_wandb', '_partial_': True, 'entity': 'example', 'project': 'uma_finetune'}, 'seed': 0, 'deterministic': False, 'runner_state_path': None, 'metadata': {'commit': 'core:None,experimental:NA', 'log_dir': '/tmp/finetune_dir/some_id/logs', 'checkpoint_dir': '/tmp/finetune_dir/some_id/checkpoints', 'results_dir': '/tmp/finetune_dir/some_id/results', 'config_path': '/tmp/finetune_dir/some_id/canonical_config.yaml', 'preemption_checkpoint_dir': '/tmp/finetune_dir/some_id/checkpoints/preemption_state', 'cluster_name': 'github', 'array_job_num': 0, 'slurm_env': {'job_id': None, 'raw_job_id': None, 'array_job_id': None, 'array_task_id': None, 'restart_count': None}}, 'graph_parallel_group_size': None, 'recursive_instantiate_runner': True}, 'tasks': [{'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'energy', 'level': 'system', 'property': 'energy', 'loss_fn': {'_target_': 'fairchem.core.modules.loss.DDPMTLoss', 'loss_fn': {'_target_': 'fairchem.core.modules.loss.PerAtomMAELoss'}, 'coefficient': 20}, 'out_spec': {'dim': [1], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'element_references': {'_target_': 'fairchem.core.modules.normalization.element_references.ElementReferences', 'element_references': {'_target_': 'torch.DoubleTensor', '_args_': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.082805460035017, 0.0, 0.0, 0.0, -3.256404920200298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]}}, 'datasets': ['omat'], 'metrics': ['mae', 'per_atom_mae']}, {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'forces', 'level': 'atom', 'property': 'forces', 'out_spec': {'dim': [3], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'datasets': ['omat'], 'inference_only': True}, {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.Task', 'name': 'stress', 'level': 'system', 'property': 'stress', 'out_spec': {'dim': [1, 9], 'dtype': 'float32'}, 'normalizer': {'_target_': 'fairchem.core.modules.normalization.normalizer.Normalizer', 'mean': 0.0, 'rmsd': 1.0}, 'datasets': ['omat'], 'inference_only': True}], 'model': {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit.initialize_finetuning_model', 'checkpoint_location': {'_target_': 'fairchem.core.calculate.pretrained_mlip.pretrained_checkpoint_path_from_name', 'model_name': 'uma-s-1'}, 'overrides': {'backbone': {'otf_graph': True, 'max_neighbors': 300, 'regress_stress': True, 'always_use_pbc': False}, 'pass_through_head_outputs': True}, 'heads': {'efs': {'module': 'fairchem.core.models.uma.escn_md.MLP_EFS_Head'}}}, 'optimizer_fn': {'_target_': 'torch.optim.AdamW', '_partial_': True, 'lr': 0.0002, 'weight_decay': 0.001}, 'cosine_lr_scheduler_fn': {'_target_': 'fairchem.core.units.mlip_unit.mlip_unit._get_consine_lr_scheduler', '_partial_': True, 'warmup_factor': 0.2, 'warmup_epochs': 0.01, 'lr_min_factor': 0.01, 'epochs': 2, 'steps': None}, 'print_every': 10, 'clip_grad_norm': 100}, 'max_epochs': 2, 'max_steps': None, 'evaluate_every_n_steps': 100, 'callbacks': [{'_target_': 'fairchem.core.components.train.train_runner.TrainCheckpointCallback', 'checkpoint_every_n_steps': 1000, 'max_saved_checkpoints': 5}, {'_target_': 'torchtnt.framework.callbacks.TQDMProgressBar'}]}}\r\n"},"key":"nphw19KfIg"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:Running in local mode with 1 ranks using device_type:cuda\r\nINFO:root:Running in local mode without elastic launch\r\nINFO:root:Setting env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\r\nINFO:root:Setting up distributed backend...\r\n"},"key":"relIjlk0r6"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:Calling runner.run() ...\r\n"},"key":"nSxaFaFSUM"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:get_dataloader::Calling batch_sampler_fn=functools.partial(<class 'fairchem.core.common.data_parallel.BalancedBatchSampler'>, batch_size=2, shuffle=True, seed=0)...\r\nWARNING:root:Disabled BalancedBatchSampler because num_replicas=1.\r\nINFO:root:rank: 0: Sampler created...\r\nINFO:root:Created BalancedBatchSampler with sampler=<fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x7274283f9670>, batch_size=2, drop_last=False\r\nINFO:root:get_dataloader::Calling Dataloader...\r\nINFO:root:get_dataloader::Done!\r\n"},"key":"Zivd4OvWgx"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:get_dataloader::Calling batch_sampler_fn=functools.partial(<class 'fairchem.core.common.data_parallel.BalancedBatchSampler'>, batch_size=2, shuffle=False, seed=0)...\r\nWARNING:root:Disabled BalancedBatchSampler because num_replicas=1.\r\nINFO:root:rank: 0: Sampler created...\r\nINFO:root:Created BalancedBatchSampler with sampler=<fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x72742aff9640>, batch_size=2, drop_last=False\r\nINFO:root:get_dataloader::Calling Dataloader...\r\nINFO:root:get_dataloader::Done!\r\n"},"key":"DlGgk7UWvN"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:httpx:HTTP Request: HEAD https://huggingface.co/facebook/UMA/resolve/main/checkpoints/uma-s-1.pt \"HTTP/1.1 302 Found\"\r\n"},"key":"SERYF2Y3Vd"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/facebook/UMA/xet-read-token/38529caa2c51a9a8a0d71f0b56b79ac33bc9eceb \"HTTP/1.1 200 OK\"\r\n\rcheckpoints/uma-s-1.pt:   0%|                       | 0.00/1.17G [00:00<?, ?B/s]"},"key":"F8j1nN4dUT"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:   0%|               | 615k/1.17G [00:00<17:20, 1.13MB/s]"},"key":"JxVLGIAMYo"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:   6%|▊             | 67.7M/1.17G [00:01<00:14, 75.5MB/s]"},"key":"y4fy7mcRrU"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  11%|█▊              | 135M/1.17G [00:01<00:08, 116MB/s]"},"key":"xypOtVhVQp"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  17%|██▊             | 202M/1.17G [00:01<00:06, 153MB/s]"},"key":"Q9laOtXsUf"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  29%|████▌           | 336M/1.17G [00:01<00:03, 274MB/s]"},"key":"otxhNcnw5O"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  40%|██████▍         | 470M/1.17G [00:02<00:01, 412MB/s]"},"key":"MgI9Meo0WG"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  54%|████████▋       | 637M/1.17G [00:02<00:01, 527MB/s]"},"key":"Es30TmSmlb"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  66%|██████████▌     | 771M/1.17G [00:02<00:00, 628MB/s]"},"key":"FZ9B4lXUYy"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  77%|████████████▎   | 905M/1.17G [00:02<00:00, 750MB/s]"},"key":"ARqdiRIxwT"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt:  89%|█████████████▎ | 1.04G/1.17G [00:02<00:00, 863MB/s]"},"key":"eLHjRruVhU"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rcheckpoints/uma-s-1.pt: 100%|███████████████| 1.17G/1.17G [00:02<00:00, 963MB/s]\rcheckpoints/uma-s-1.pt: 100%|███████████████| 1.17G/1.17G [00:02<00:00, 442MB/s]\r\n"},"key":"btc2ANzK78"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"WARNING:root:If 'dataset_list' is provided in the config, the code assumes that each dataset maps to itself. Please use 'dataset_mapping' as 'dataset_list' is deprecated and will be removed in the future.\r\n"},"key":"mMOBXrqnmZ"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"WARNING:root:initialize_finetuning_model starting from checkpoint_location: /home/runner/.cache/fairchem/models--facebook--UMA/snapshots/38529caa2c51a9a8a0d71f0b56b79ac33bc9eceb/checkpoints/uma-s-1.pt\r\n"},"key":"Q9KmA4FnNS"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:Train Dataloader size 1\r\nINFO:root:Eval Dataloader size 1\r\nINFO:root:No existing checkpoints found, starting from scratch\r\nINFO:torchtnt.framework.fit:Started fit with max_epochs=2 max_steps=None max_train_steps_per_epoch=None max_eval_steps_per_epoch=None evaluate_every_n_steps=100 evaluate_every_n_epochs=1 \r\nINFO:torchtnt.framework.train:Started train with max_epochs=2, max_steps=None, max_steps_per_epoch=None\r\n"},"key":"waDsEM6Irg"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:on_train_start: setting sampler state to 0, 0\r\nINFO:root:at beginning of epoch 0, setting sampler start step to 0\r\nINFO:torchtnt.framework.train:Started train epoch\r\nINFO:root:at beginning of epoch 0, setting sampler start step to 0\r\n\rTrain Epoch 0:   0%|                                     | 0/1 [00:00<?, ?it/s]\r\n"},"key":"RnhCNoqX24"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:Saved dcp checkpoint to /tmp/finetune_dir/some_id/checkpoints/step_0\r\n"},"key":"op57IwVGON"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:0: Expert variance: 3.60e-07,1.19e-02,7.17e-07,3.88e-07,4.74e-04,7.71e-07,4.15e-07,1.53e-02,8.34e-07,2.89e-05,1.65e-02,7.07e-07,7.77e-07,1.01e-06,2.53e-07,2.40e-07,3.66e-07,5.95e-04,1.57e-05,9.03e-04,1.30e-06,1.34e-04,4.34e-07,5.28e-07,9.35e-07,3.97e-07,9.43e-07,5.13e-05,4.00e-03,6.28e-07,6.77e-06,4.84e-05\r\nINFO:root:0: Expert mean: 6.88e-03,1.02e-01,6.92e-03,6.72e-03,2.17e-02,6.83e-03,6.69e-03,1.28e-01,7.05e-03,1.22e-02,9.99e-02,7.17e-03,6.82e-03,7.00e-03,6.73e-03,6.83e-03,7.01e-03,3.28e-01,1.25e-02,5.07e-02,6.99e-03,1.45e-02,6.66e-03,7.03e-03,6.87e-03,7.00e-03,7.11e-03,1.17e-02,2.01e-01,6.74e-03,8.92e-03,3.75e-02\r\n"},"key":"Y3nm9Ue0vt"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"/home/runner/work/_tool/Python/3.12.12/x64/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:367: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\r\n  _warn_get_lr_called_within_step(self)\r\nINFO:root:{'train/loss': 1.2937600874006705, 'train/lr': 4e-05, 'train/step': 0, 'train/epoch': 0.0, 'train/samples_per_second(approx)': 0.05171729511048724, 'train/atoms_per_second(approx)': 1.241215082651694, 'train/num_atoms_on_rank': 48, 'train/num_samples_on_rank': 2}\r\n\rTrain Epoch 0: 100%|█████████████████████████████| 1/1 [00:38<00:00, 38.75s/it]\r\nINFO:torchtnt.framework.train:Reached end of train dataloader\r\n\rTrain Epoch 0: 100%|█████████████████████████████| 1/1 [00:38<00:00, 38.75s/it]\r\n\r\nINFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\r\n\rEval Epoch 0:   0%|                                      | 0/1 [00:00<?, ?it/s]\r\n"},"key":"pbfoJanAD9"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rEval Epoch 0: 100%|██████████████████████████████| 1/1 [00:00<00:00,  9.91it/s]\r\nINFO:root:Done eval epoch, aggregating metrics\r\nINFO:root:Finished aggregating metrics: \r\n  val/atoms_per_second: 957.5695\r\n  val/epoch: 0.0000\r\n  val/loss: 61.0236\r\n  val/omat.val,energy,mae: 97.6377\r\n  val/omat.val,energy,per_atom_mae: 3.0512\r\n\r\n\rEval Epoch 0: 100%|██████████████████████████████| 1/1 [00:00<00:00,  9.84it/s]\r\n\r\nINFO:torchtnt.framework.train:Ended train epoch\r\nINFO:torchtnt.framework.train:After train epoch, train progress: num_epochs_completed = 1, num_steps_completed = 1\r\nINFO:torchtnt.framework.train:Started train epoch\r\nINFO:root:at beginning of epoch 1, setting sampler start step to 0\r\n\rTrain Epoch 1:   0%|                                     | 0/1 [00:00<?, ?it/s]\r\n"},"key":"sLLpRUFmFe"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"\rTrain Epoch 1: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\r\nINFO:torchtnt.framework.train:Reached end of train dataloader\r\n\rTrain Epoch 1: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\r\n\r\nINFO:torchtnt.framework.evaluate:Started evaluate with max_steps_per_epoch=None\r\n\rEval Epoch 1:   0%|                                      | 0/1 [00:00<?, ?it/s]\r\n"},"key":"i13iXH3vKu"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:Done eval epoch, aggregating metrics\r\nINFO:root:Finished aggregating metrics: \r\n  val/atoms_per_second: 998.7367\r\n  val/epoch: 0.0000\r\n  val/loss: 61.0235\r\n  val/omat.val,energy,mae: 97.6376\r\n  val/omat.val,energy,per_atom_mae: 3.0512\r\n\r\n\rEval Epoch 1: 100%|██████████████████████████████| 1/1 [00:00<00:00, 10.22it/s]\r\n\r\nINFO:torchtnt.framework.train:Ended train epoch\r\nINFO:torchtnt.framework.train:After train epoch, train progress: num_epochs_completed = 2, num_steps_completed = 2\r\nINFO:root:Training Completed 2 steps\r\n"},"key":"sDcA4DTyIA"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"INFO:root:Saved dcp checkpoint to /tmp/finetune_dir/some_id/checkpoints/final\r\nINFO:torchtnt.framework.fit:Finished fit\r\n"},"key":"ugSBstI6il"}],"key":"F00N43hWmc"}],"key":"P4zoa7GCGi"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"children":[{"type":"text","value":"The basic YAML configuration looks like the following:","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"key":"vjsxpxOuYz"}],"key":"PG1XCwwZL1"},{"type":"code","lang":"yaml","value":"job:\n  device_type: CUDA\n  scheduler:\n    mode: LOCAL\n    ranks_per_node: 1\n    num_nodes: 1\n  debug: True\n  run_dir: /tmp/uma_finetune_runs/\n  run_name: uma_finetune\n  logger:\n    _target_: fairchem.core.common.logger.WandBSingletonLogger.init_wandb\n    _partial_: true\n    entity: example\n    project: uma_finetune\n\n\nbase_model_name: uma-s-1p1\nmax_neighbors: 300\nepochs: 1\nsteps: null\nbatch_size: 2\nlr: 4e-4\n\ntrain_dataloader ...\neval_dataloader ...\nrunner ...","position":{"start":{"line":92,"column":1},"end":{"line":119,"column":1}},"key":"dWhB4wwiMK"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Configuration Parameters","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"ku7ztSXnM4"}],"key":"IlpXzLpObW"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":124,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":124,"column":1},"end":{"line":131,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"strong","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"base_model_name","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"UQdQUrwm52"}],"key":"McwZ8NUzLy"},{"type":"text","value":": Refers to a model name that can be retrieved from ","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"ptZvxWPlrC"},{"type":"link","url":"https://huggingface.co/facebook/UMA","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"HuggingFace","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"tOyXaeeiLq"}],"urlSource":"https://huggingface.co/facebook/UMA","key":"p4HDtfo65I"},{"type":"text","value":". If you want to use your custom UMA checkpoint, provide the path directly in the runner:","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"UVJP4IR8uV"}],"key":"WmulmBRXdp"},{"type":"code","lang":"yaml","value":"model:\n  _target_: fairchem.core.units.mlip_unit.mlip_unit.initialize_finetuning_model\n  checkpoint_location: /path/to/your/checkpoint.pt","position":{"start":{"line":126,"column":1},"end":{"line":130,"column":1}},"key":"nG0TU4oYZg"}],"key":"iMaMGwUj8c"},{"type":"listItem","spread":true,"position":{"start":{"line":132,"column":1},"end":{"line":133,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"children":[{"type":"strong","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"children":[{"type":"text","value":"max_neighbors","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"XQlx6Ypx7y"}],"key":"PPCYKYcJWQ"},{"type":"text","value":": The number of neighbors used for the equivariant SO2 convolutions. 300 is the default used in UMA training, but if you don’t have a lot of memory, 100 is usually fine to ensure smoothness of the potential (see the ","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"woj3DRaLOe"},{"type":"link","url":"https://arxiv.org/abs/2502.12147","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"children":[{"type":"text","value":"ESEN paper","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"eGWn6ql9xS"}],"urlSource":"https://arxiv.org/abs/2502.12147","key":"XeeHw4Pw5T"},{"type":"text","value":").","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"fzfsPnzC6e"}],"key":"wmQPixmgh8"}],"key":"MCJwh0JlEh"},{"type":"listItem","spread":true,"position":{"start":{"line":134,"column":1},"end":{"line":135,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"strong","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"text","value":"epochs","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"n2w3iezjG6"}],"key":"tI2YToWwjD"},{"type":"text","value":", ","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"Bq78Ug5sRj"},{"type":"strong","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"text","value":"steps","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"SC8Xp4gUcQ"}],"key":"WlkD1jnaT0"},{"type":"text","value":": Choose to either run for an integer number of epochs or steps. Only 1 can be specified; the other must be null.","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"wZ7F1cmeU1"}],"key":"HLWJq2RBXI"}],"key":"scFku4JSgC"},{"type":"listItem","spread":true,"position":{"start":{"line":136,"column":1},"end":{"line":137,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"strong","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"batch_size","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"OrcZyCydof"}],"key":"nhdmjTUU4o"},{"type":"text","value":": In this configuration we use the batch sampler. Start with the largest batch size that can fit on your system without running out of memory. However, don’t use a batch size so large that you complete training in very few steps. The optimal batch size is usually the one that minimizes the final validation loss for a fixed compute budget.","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"ijOh4Hxp9e"}],"key":"sTyYWxMynV"}],"key":"GQ250cMZA5"},{"type":"listItem","spread":true,"position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"strong","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"text","value":"lr","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"y7V5PMx9aj"}],"key":"J1m1OnifUB"},{"type":"text","value":", ","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"JZ134TDX6H"},{"type":"strong","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"text","value":"weight_decay","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"JlLYUyPrZ3"}],"key":"XUyxiDLQiH"},{"type":"text","value":": These are standard learning parameters. The recommended values we use are the defaults.","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"DQUsbPCeiM"}],"key":"qSPcsPNUJb"}],"key":"gpAaYszUl7"}],"key":"mg6e3ACZvE"}],"class":"dropdown","key":"Trla4Tic2V"},{"type":"heading","depth":3,"position":{"start":{"line":141,"column":1},"end":{"line":141,"column":1}},"children":[{"type":"text","value":"Logging and Artifacts","position":{"start":{"line":141,"column":1},"end":{"line":141,"column":1}},"key":"Dm0MwhaemR"}],"identifier":"logging-and-artifacts","label":"Logging and Artifacts","html_id":"logging-and-artifacts","implicit":true,"key":"iCjrD2FX0W"},{"type":"paragraph","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"children":[{"type":"text","value":"For logging and checkpoints, all artifacts are stored in the location specified in ","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"iDZ7Knnu7l"},{"type":"inlineCode","value":"job.run_dir","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"CYi0DLj1z5"},{"type":"text","value":". The visual logger we support is ","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"PWVdiRg9ME"},{"type":"link","url":"https://wandb.ai/site/","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"children":[{"type":"text","value":"Weights and Biases","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"vZ4xvZHbiT"}],"urlSource":"https://wandb.ai/site/","key":"pVbcVsLFgY"},{"type":"text","value":".","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"JfGn95QkYJ"}],"key":"j5mrDZ9Fcn"},{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Warning","key":"IR3bL0Rjuh"}],"key":"sei8Abm8gP"},{"type":"paragraph","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"Tensorboard is no longer supported. You must set up your W&B account separately and ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"FAqDPbImqd"},{"type":"inlineCode","value":"job.debug","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"qNmhY8k9UU"},{"type":"text","value":" must be set to ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"WgippGNT3i"},{"type":"inlineCode","value":"False","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"Rd3FfHnfZ6"},{"type":"text","value":" for W&B logging to work.","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"spWCOYlCw8"}],"key":"byBciViDxg"}],"key":"raIt3C4gnw"},{"type":"heading","depth":3,"position":{"start":{"line":149,"column":1},"end":{"line":149,"column":1}},"children":[{"type":"text","value":"Distributed Training","position":{"start":{"line":149,"column":1},"end":{"line":149,"column":1}},"key":"xZN9Puqzv5"}],"identifier":"distributed-training","label":"Distributed Training","html_id":"distributed-training","implicit":true,"key":"k0AEyCzpAk"},{"type":"paragraph","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"children":[{"type":"text","value":"We support multi-GPU distributed training without additional infrastructure and multi-node distributed training on ","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"key":"eizztfCJ5F"},{"type":"link","url":"https://slurm.schedmd.com/documentation.html","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"children":[{"type":"text","value":"SLURM","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"key":"Fu5FzSh0QX"}],"urlSource":"https://slurm.schedmd.com/documentation.html","key":"kT4hyqH7Ex"},{"type":"text","value":" only.","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"key":"Ftdc5bZVpn"}],"key":"VcHBzBtBHG"},{"type":"paragraph","position":{"start":{"line":153,"column":1},"end":{"line":153,"column":1}},"children":[{"type":"strong","position":{"start":{"line":153,"column":1},"end":{"line":153,"column":1}},"children":[{"type":"text","value":"Multi-GPU locally:","position":{"start":{"line":153,"column":1},"end":{"line":153,"column":1}},"key":"khdy9ZiHal"}],"key":"Hf4d0ZG7cn"},{"type":"text","value":" Simply set ","position":{"start":{"line":153,"column":1},"end":{"line":153,"column":1}},"key":"Pj2o65bsKf"},{"type":"inlineCode","value":"job.scheduler.ranks_per_node=N","position":{"start":{"line":153,"column":1},"end":{"line":153,"column":1}},"key":"Ti5AN5zS85"},{"type":"text","value":" where N is the number of GPUs you want to train on.","position":{"start":{"line":153,"column":1},"end":{"line":153,"column":1}},"key":"H75M8cDNDy"}],"key":"B2SpLHgrVn"},{"type":"paragraph","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"children":[{"type":"strong","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"children":[{"type":"text","value":"Multi-node on SLURM:","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"y9yuZhJ3A2"}],"key":"eYbeeSeOSv"},{"type":"text","value":" Change ","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"dnJJQWp8AP"},{"type":"inlineCode","value":"job.scheduler.mode=SLURM","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"L9O1vnn4R4"},{"type":"text","value":" and set both ","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"ljhb7aV1iR"},{"type":"inlineCode","value":"job.scheduler.ranks_per_node","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"Ns5viC137f"},{"type":"text","value":" and ","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"gAm7XFT81j"},{"type":"inlineCode","value":"job.scheduler.num_nodes","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"gObA4wiqup"},{"type":"text","value":" to the desired values.","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"Z5z8pr9WsK"}],"key":"f7Le8rqtmV"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"UAyzWeb3lE"}],"key":"XsKtfGlngk"},{"type":"paragraph","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"stOGM9OBRK"},{"type":"inlineCode","value":"run_dir","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"rpv9fNBOER"},{"type":"text","value":" must be in a shared network accessible mount for multi-node training to work.","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"U0yWgfQPsp"}],"key":"jyPzgBnxF6"}],"key":"Y76vZ9QMi3"},{"type":"heading","depth":3,"position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"children":[{"type":"text","value":"Resuming Runs","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"ektahRJ3aw"}],"identifier":"resuming-runs","label":"Resuming Runs","html_id":"resuming-runs","implicit":true,"key":"IZ9yVFwyP6"},{"type":"paragraph","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"children":[{"type":"text","value":"To resume from a checkpoint in the middle of a run, find the checkpoint folder at the step you want and use the same fairchem command:","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"key":"aFBxPA519U"}],"key":"vblflk0d86"}],"key":"BB4MXWCxot"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"! fairchem -c /tmp/finetune_dir/some_id/checkpoints/final/resume.yaml","visibility":"show","key":"al2eTkQcMd"},{"type":"outputs","id":"cfJotJqLJH7r3jm8I0Z0u","children":[],"visibility":"show","key":"iTYxK9FVU8"}],"data":{"tags":["skip-execution"]},"visibility":"show","key":"Oi2KtsIV5G"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"children":[{"type":"text","value":"Running Inference on the Fine-tuned Model","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"key":"BbPwFjRIE7"}],"identifier":"running-inference-on-the-fine-tuned-model","label":"Running Inference on the Fine-tuned Model","html_id":"running-inference-on-the-fine-tuned-model","implicit":true,"key":"uGheQp5lRl"},{"type":"paragraph","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"children":[{"type":"text","value":"Inference is run in the same way as the UMA models, except you need to load the checkpoint from a local path.","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"key":"cej6MmOB9K"}],"key":"mhHAJh2u6D"},{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Warning","key":"olQ4fhtxDm"}],"key":"uC6iAPPb0z"},{"type":"paragraph","position":{"start":{"line":175,"column":1},"end":{"line":175,"column":1}},"children":[{"type":"text","value":"You must use the same task that you used for fine-tuning!","position":{"start":{"line":175,"column":1},"end":{"line":175,"column":1}},"key":"o7l51uxeXm"}],"key":"B3hDTct3WA"}],"key":"AkbmBPfjG4"}],"key":"POmjp36VAE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from fairchem.core.units.mlip_unit import load_predict_unit\nfrom fairchem.core import FAIRChemCalculator\n\npredictor = load_predict_unit(\"/tmp/finetune_dir/some_id/checkpoints/final/inference_ckpt.pt\")\ncalc = FAIRChemCalculator(predictor, task_name=\"omat\")","key":"bbUQkuIdwD"},{"type":"outputs","id":"8iBuSY52HHgOI5iZEWvpb","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stderr","text":"WARNING:root:device was not explicitly set, using device='cuda'.\n"},"key":"FwhSszQwtI"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stderr","text":"WARNING:root:If 'dataset_list' is provided in the config, the code assumes that each dataset maps to itself. Please use 'dataset_mapping' as 'dataset_list' is deprecated and will be removed in the future.\n"},"key":"fS6Ma3sPV7"}],"key":"rGAXtFmIyT"}],"key":"J3jrRB3Wys"}],"key":"owHO1Pp53m"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Evaluating Pretrained Models","url":"/evaluation","group":"AI/ML Models & Usage"},"next":{"title":"Calculation Workflows with FAIRChem Models","url":"/workflows","group":"AI/ML Models & Usage"}}},"domain":"http://localhost:3000"}