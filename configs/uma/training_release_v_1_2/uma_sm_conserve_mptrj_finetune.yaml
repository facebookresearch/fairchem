defaults:
  - cluster: h100_local
  - dataset: mptrj_omat_finetune
  - element_refs: mptrj_lin_refs
  - tasks: mptrj_omat_conserving_stress
  - _self_

job:
  device_type: ${cluster.device}
  scheduler:
    mode: ${cluster.mode}
    ranks_per_node: ${cluster.ranks_per_node}
    # num_nodes: 8
    slurm:
      account: ${cluster.account}
      qos: ocp_high
      mem_gb: ${cluster.mem_gb}
  debug: ${cluster.debug}
  run_dir: ${cluster.run_dir}
  run_name: uma_v1.2_sm_final_conserve_mptrj_finetune
  logger:
    _target_: fairchem.core.common.logger.WandBSingletonLogger.init_wandb
    _partial_: true
    entity: fairchem
    project: uma

starting_checkpoint: /checkpoint/ocp/shared/uma/202508-2813-5759-3f63/checkpoints/final/inference_ckpt.pt
cutoff_radius: 6.0
max_neighbors: 300
epochs: 1
steps: null # 1000000 # 140B atoms, 128 ranks, max atoms 700 (mean atoms 650)
max_atoms: 80
min_atoms: 8
bf16: False
cpu_graph: True
normalizer_rmsd: 0.6274358

energy_coef: 20
force_coef: 20
stress_coef: 5

regress_stress: True

omat_forces_key: omat_forces

exclude_keys: [
  "id", # only oc20,oc22 have this
  "fid", # only oc20,oc22 have this
  "absolute_idx", # only ani has this
  "target_pos", # only ani has this
  "ref_energy", # only ani/geom have this
  "pbc", # only ani/transition1x have this
  "nads", # oc22
  "oc22", # oc22
  "formation_energy", # spice
  "total_charge", # spice
]

train_dataset:
  _target_: fairchem.core.datasets.mt_concat_dataset.create_concat_dataset
  dataset_configs:
    omat: ${dataset.omat_train}
  combined_dataset_config: { sampling: {type: temperature, temperature: 1.0} }

val_dataset:
  _target_: fairchem.core.datasets.mt_concat_dataset.create_concat_dataset
  dataset_configs:
    omat: ${dataset.omat_val}
  combined_dataset_config: { sampling: {type: temperature, temperature: 1.0} }

train_dataloader:
  _target_: fairchem.core.components.common.dataloader_builder.get_dataloader
  dataset: ${train_dataset}
  batch_sampler_fn:
    _target_: fairchem.core.datasets.samplers.max_atom_distributed_sampler.MaxAtomDistributedBatchSampler
    _partial_: True
    max_atoms: ${max_atoms}
    min_atoms: ${min_atoms}
    shuffle: True
    seed: 0
  num_workers: ${cluster.dataloader_workers}
  collate_fn:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter
    tasks: ${tasks}
    exclude_keys: ${exclude_keys}

eval_dataloader:
  _target_: fairchem.core.components.common.dataloader_builder.get_dataloader
  dataset: ${val_dataset}
  batch_sampler_fn:
    _target_: fairchem.core.datasets.samplers.max_atom_distributed_sampler.MaxAtomDistributedBatchSampler
    _partial_: True
    max_atoms: ${max_atoms}
    min_atoms: ${min_atoms}
    shuffle: False
    seed: 0
  num_workers: ${cluster.dataloader_workers}
  collate_fn:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter
    tasks: ${tasks}
    exclude_keys: ${exclude_keys}


heads:
  energyandforcehead:
    module: fairchem.core.models.uma.escn_moe.DatasetSpecificSingleHeadWrapper
    head_cls: fairchem.core.models.uma.escn_md.MLP_EFS_Head
    head_kwargs:
      wrap_property: False
    dataset_names:
      - omat

runner:
  _target_: fairchem.core.components.train.train_runner.TrainEvalRunner
  train_dataloader: ${train_dataloader}
  eval_dataloader: ${eval_dataloader}
  train_eval_unit:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.MLIPTrainEvalUnit
    job_config: ${job}
    tasks: ${tasks}
    model:
      _target_: fairchem.core.units.mlip_unit.mlip_unit.initialize_finetuning_model
      checkpoint_location: ${starting_checkpoint}
      overrides:
        backbone:
          max_neighbors: ${max_neighbors}
          regress_stress: ${regress_stress}
          direct_forces: False
        pass_through_head_outputs: True
      heads: ${heads}
    optimizer_fn:
      _target_: torch.optim.AdamW
      _partial_: true
      lr: 2e-4
      weight_decay: 1e-3
    cosine_lr_scheduler_fn:
      _target_: fairchem.core.units.mlip_unit.mlip_unit._get_consine_lr_scheduler
      _partial_: true
      warmup_factor: 0.2
      warmup_epochs: 0.01
      lr_min_factor: 0.02
      epochs: ${epochs}
      steps: ${steps}
    print_every: 10
    clip_grad_norm: 100
    bf16: ${bf16}
  max_epochs: ${epochs}
  max_steps: ${steps}
  evaluate_every_n_steps: 5000
  callbacks:
    - _target_: fairchem.core.common.profiler_utils.ProfilerCallback
      job_config: ${job}
    - _target_: fairchem.core.components.train.train_runner.TrainCheckpointCallback
      checkpoint_every_n_steps: 5000
      max_saved_checkpoints: 5
